{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '01_v1_29'\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "#'microsoft/deberta-base'\n",
    "#'microsoft/deberta-v3-large'\n",
    "LR = 4e-5 #2e-5 #8e-6\n",
    "HEAD_LR = 2e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 8\n",
    "VAL_BS = 8\n",
    "ACCUM_STEP = 1\n",
    "HIDDEN_DROP_PROB = 0\n",
    "P_DROP = 0\n",
    "RNN = 'none'\n",
    "WARMUP_RATIO = 0.1\n",
    "HEAD = 'simple'\n",
    "AUG = 'false'\n",
    "MIXUP_ALPHA = 0\n",
    "P_AUG = 0\n",
    "AUG_STOP_EPOCH = 0\n",
    "MSD = 'false'\n",
    "MULTI_LAYERS = 1\n",
    "EVAL_STEP = -1\n",
    "NUM_LABELS = 6\n",
    "NUM_LABELS_2 = -1\n",
    "FP16 = 'true'\n",
    "WD = 0.01\n",
    "FREEZE = 'false'\n",
    "MULTI_TASK = 'false' \n",
    "W_MT = 0 \n",
    "AWP = 'false'\n",
    "AWP_LR = 0\n",
    "AWP_EPS = 0\n",
    "AWP_START_EPOCH = -1\n",
    "#PRETRAINED_DETECTOR_PATH = f'../../input/tascj/result/deberta_base_fold0.pth'\n",
    "PRETRAINED_DETECTOR_PATH = 'none' #f'../../05_Detection/exp/result/05_v2_09/model_seed100_fold0_swa.pth'\n",
    "MASK_PROB = 0 #0.8\n",
    "MASK_RATIO = 0 #0.3\n",
    "SCHEDULER = 'cosine_hard'\n",
    "CP = 'false'\n",
    "WINDOW_SIZE = -1 #512\n",
    "INNER_LEN = -1 #384\n",
    "EDGE_LEN = -1 #64\n",
    "MAX_LEN = 512\n",
    "\n",
    "GRAD_CLIP = 1\n",
    "\n",
    "LOSS = 'smoothl1'#'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-09-15 12:00:40.776243: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-09-15 12:00:40.776263: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.79it/s, loss=0.415]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.52it/s]\n",
      "epoch 1: trn_loss = 0.4151, val_loss = 0.1100, trn_score = 1.1115, val_score = 0.4696\n",
      "lr :  [1.6448936074913938e-05, 1.6448936074913938e-05, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:45<00:00,  3.72it/s, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:22<00:00,  4.44it/s]\n",
      "epoch 2: trn_loss = 0.1083, val_loss = 0.1073, trn_score = 0.4665, val_score = 0.4636\n",
      "lr :  [9.948515937865382e-06, 9.948515937865382e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:44<00:00,  3.73it/s, loss=0.104]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.53it/s]\n",
      "epoch 3: trn_loss = 0.1043, val_loss = 0.1040, trn_score = 0.4576, val_score = 0.4564\n",
      "lr :  [4.6536441051674915e-06, 4.6536441051674915e-06, 2.3268220525837457e-05]\n",
      "100%|████████████████████████████| 391/391 [01:44<00:00,  3.75it/s, loss=0.0978]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.56it/s]\n",
      "epoch 4: trn_loss = 0.0978, val_loss = 0.1058, trn_score = 0.4429, val_score = 0.4604\n",
      "lr :  [1.1993734426661985e-06, 1.1993734426661985e-06, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [01:43<00:00,  3.77it/s, loss=0.0951]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.59it/s]\n",
      "epoch 5: trn_loss = 0.0951, val_loss = 0.1025, trn_score = 0.4367, val_score = 0.4531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-09-15 12:11:30.417326: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-09-15 12:11:30.417348: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.78it/s, loss=0.404]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.59it/s]\n",
      "epoch 1: trn_loss = 0.4041, val_loss = 0.1126, trn_score = 1.0943, val_score = 0.4760\n",
      "lr :  [1.6448936074913938e-05, 1.6448936074913938e-05, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.78it/s, loss=0.114]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.61it/s]\n",
      "epoch 2: trn_loss = 0.1136, val_loss = 0.1044, trn_score = 0.4778, val_score = 0.4580\n",
      "lr :  [9.948515937865382e-06, 9.948515937865382e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:42<00:00,  3.80it/s, loss=0.101]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.63it/s]\n",
      "epoch 3: trn_loss = 0.1009, val_loss = 0.1102, trn_score = 0.4499, val_score = 0.4710\n",
      "lr :  [4.6536441051674915e-06, 4.6536441051674915e-06, 2.3268220525837457e-05]\n",
      "100%|████████████████████████████| 391/391 [01:42<00:00,  3.81it/s, loss=0.0895]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.63it/s]\n",
      "epoch 4: trn_loss = 0.0895, val_loss = 0.1039, trn_score = 0.4233, val_score = 0.4567\n",
      "lr :  [1.1993734426661985e-06, 1.1993734426661985e-06, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [01:42<00:00,  3.81it/s, loss=0.0802]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.64it/s]\n",
      "epoch 5: trn_loss = 0.0802, val_loss = 0.1071, trn_score = 0.4004, val_score = 0.4636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 1\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-09-15 12:22:12.064317: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-09-15 12:22:12.064341: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [01:44<00:00,  3.76it/s, loss=0.422]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.56it/s]\n",
      "epoch 1: trn_loss = 0.4217, val_loss = 0.1061, trn_score = 1.1268, val_score = 0.4619\n",
      "lr :  [1.6448936074913938e-05, 1.6448936074913938e-05, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.77it/s, loss=0.107]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.61it/s]\n",
      "epoch 2: trn_loss = 0.1070, val_loss = 0.1013, trn_score = 0.4635, val_score = 0.4509\n",
      "lr :  [9.948515937865382e-06, 9.948515937865382e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.78it/s, loss=0.102]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.61it/s]\n",
      "epoch 3: trn_loss = 0.1025, val_loss = 0.1000, trn_score = 0.4534, val_score = 0.4478\n",
      "lr :  [4.6536441051674915e-06, 4.6536441051674915e-06, 2.3268220525837457e-05]\n",
      "100%|████████████████████████████| 391/391 [01:43<00:00,  3.78it/s, loss=0.0979]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.63it/s]\n",
      "epoch 4: trn_loss = 0.0979, val_loss = 0.1021, trn_score = 0.4430, val_score = 0.4527\n",
      "lr :  [1.1993734426661985e-06, 1.1993734426661985e-06, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [01:43<00:00,  3.78it/s, loss=0.0957]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.63it/s]\n",
      "epoch 5: trn_loss = 0.0957, val_loss = 0.0985, trn_score = 0.4380, val_score = 0.4442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 2\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-09-15 12:32:57.228133: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-09-15 12:32:57.228153: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.77it/s, loss=0.411]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.56it/s]\n",
      "epoch 1: trn_loss = 0.4108, val_loss = 0.1156, trn_score = 1.1399, val_score = 0.4820\n",
      "lr :  [1.6448936074913938e-05, 1.6448936074913938e-05, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.77it/s, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.60it/s]\n",
      "epoch 2: trn_loss = 0.1080, val_loss = 0.1092, trn_score = 0.4661, val_score = 0.4680\n",
      "lr :  [9.948515937865382e-06, 9.948515937865382e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:43<00:00,  3.79it/s, loss=0.101]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.61it/s]\n",
      "epoch 3: trn_loss = 0.1009, val_loss = 0.1057, trn_score = 0.4500, val_score = 0.4606\n",
      "lr :  [4.6536441051674915e-06, 4.6536441051674915e-06, 2.3268220525837457e-05]\n",
      "100%|████████████████████████████| 391/391 [01:43<00:00,  3.79it/s, loss=0.0963]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.62it/s]\n",
      "epoch 4: trn_loss = 0.0963, val_loss = 0.1051, trn_score = 0.4395, val_score = 0.4591\n",
      "lr :  [1.1993734426661985e-06, 1.1993734426661985e-06, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [01:43<00:00,  3.78it/s, loss=0.0908]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:21<00:00,  4.48it/s]\n",
      "epoch 5: trn_loss = 0.0908, val_loss = 0.1071, trn_score = 0.4266, val_score = 0.4637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 3\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-09-15 12:43:41.986028: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-09-15 12:43:41.986050: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [01:46<00:00,  3.66it/s, loss=0.393]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:22<00:00,  4.44it/s]\n",
      "epoch 1: trn_loss = 0.3926, val_loss = 0.1136, trn_score = 1.0690, val_score = 0.4778\n",
      "lr :  [1.6448936074913938e-05, 1.6448936074913938e-05, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:46<00:00,  3.68it/s, loss=0.117]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:22<00:00,  4.43it/s]\n",
      "epoch 2: trn_loss = 0.1169, val_loss = 0.1201, trn_score = 0.4851, val_score = 0.4917\n",
      "lr :  [9.948515937865382e-06, 9.948515937865382e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:45<00:00,  3.70it/s, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:22<00:00,  4.43it/s]\n",
      "epoch 3: trn_loss = 0.1030, val_loss = 0.1059, trn_score = 0.4546, val_score = 0.4610\n",
      "lr :  [4.6536441051674915e-06, 4.6536441051674915e-06, 2.3268220525837457e-05]\n",
      "100%|█████████████████████████████| 391/391 [01:45<00:00,  3.70it/s, loss=0.096]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:22<00:00,  4.42it/s]\n",
      "epoch 4: trn_loss = 0.0960, val_loss = 0.1047, trn_score = 0.4384, val_score = 0.4582\n",
      "lr :  [1.1993734426661985e-06, 1.1993734426661985e-06, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [01:45<00:00,  3.70it/s, loss=0.0889]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:22<00:00,  4.40it/s]\n",
      "epoch 5: trn_loss = 0.0889, val_loss = 0.1062, trn_score = 0.4220, val_score = 0.4615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 4\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../$VERSION/swa.py --work_dir ./result/$VERSION/ --fold 0 --seed $SEED --epochs '5'\n",
    "!python ../$VERSION/swa.py --work_dir ./result/$VERSION/ --fold 1 --seed $SEED --epochs '4'\n",
    "!python ../$VERSION/swa.py --work_dir ./result/$VERSION/ --fold 2 --seed $SEED --epochs '5'\n",
    "!python ../$VERSION/swa.py --work_dir ./result/$VERSION/ --fold 3 --seed $SEED --epochs '4'\n",
    "!python ../$VERSION/swa.py --work_dir ./result/$VERSION/ --fold 4 --seed $SEED --epochs '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}_swa.pth'\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "--fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 1\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}_swa.pth'\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "--fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 2\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}_swa.pth'\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "--fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 3\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}_swa.pth'\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "--fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 4\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}_swa.pth'\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "--fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds = []\n",
    "for fold in range(5):\n",
    "    tmp_df = pd.read_csv(f'./result/{VERSION}/pred_fold{fold}.csv')\n",
    "    preds.append(tmp_df)\n",
    "    \n",
    "pred_df = pd.concat(preds, axis=0).reset_index(drop=True)\n",
    "train_df = pd.read_csv('../../input/feedback-prize-english-language-learning/train.csv')\n",
    "\n",
    "oof_df = train_df[['text_id']].merge(pred_df, on='text_id', how='left')\n",
    "oof_df.to_csv(f'./result/{VERSION}/oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.shape, oof_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
