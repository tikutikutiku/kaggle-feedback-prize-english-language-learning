{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '01_v1_61'\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "#'bert-large-cased'\n",
    "#'bert-large-cased-whole-word-masking'\n",
    "#'albert-large-v2'\n",
    "#'facebook/bart-large'\n",
    "#'xlm-roberta-large'\n",
    "#'deepset/roberta-large-squad2'\n",
    "#'google/electra-large-discriminator'\n",
    "#'sentence-transformeres/paraphrase-mpnet-base-v2'\n",
    "#'funnel-transformer/large-base'\n",
    "#'facebook/bart-base'\n",
    "#'distilroberta-base'\n",
    "#'deepset/roberta-base-squad2'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'roberta-large'\n",
    "#'roberta-base'\n",
    "#'microsoft/deberta-v3-large'\n",
    "#'microsoft/deberta-base'\n",
    "LR = 2e-5 #8e-6\n",
    "HEAD_LR = 2e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 16 #8\n",
    "VAL_BS = 16 #8\n",
    "ACCUM_STEP = 1\n",
    "HIDDEN_DROP_PROB = 0\n",
    "P_DROP = 0\n",
    "RNN = 'none'\n",
    "WARMUP_RATIO = 0.1\n",
    "HEAD = 'simple'\n",
    "AUG = 'false'\n",
    "MIXUP_ALPHA = 0\n",
    "P_AUG = 0\n",
    "AUG_STOP_EPOCH = 0\n",
    "MSD = 'false'\n",
    "MULTI_LAYERS = 1\n",
    "EVAL_STEP_START_EPOCH = -1\n",
    "EVAL_STEP = -1\n",
    "NUM_LABELS = 6\n",
    "NUM_LABELS_2 = -1\n",
    "FP16 = 'true'\n",
    "WD = 0.01\n",
    "FREEZE = 'false'\n",
    "MULTI_TASK = 'false' \n",
    "W_MT = 0 \n",
    "AWP = 'false'\n",
    "AWP_LR = 0\n",
    "AWP_EPS = 0\n",
    "AWP_START_EPOCH = -1\n",
    "#PRETRAINED_DETECTOR_PATH = f'../../input/tascj/result/deberta_base_fold0.pth'\n",
    "PRETRAINED_DETECTOR_PATH = 'none' #f'../../05_Detection/exp/result/05_v2_09/model_seed100_fold0_swa.pth'\n",
    "MASK_PROB = 0 #0.8\n",
    "MASK_RATIO = 0 #0.3\n",
    "SCHEDULER = 'cosine_hard'\n",
    "CP = 'true' #'false'\n",
    "WINDOW_SIZE = -1 #512\n",
    "INNER_LEN = -1 #384\n",
    "EDGE_LEN = -1 #64\n",
    "MAX_LEN = 512\n",
    "\n",
    "GRAD_CLIP = 1\n",
    "\n",
    "LOSS = 'smoothl1'#'mse'\n",
    "\n",
    "CROP_PROB = 0 #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 21:14:30.023273: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 21:14:30.023296: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [02:11<00:00,  1.48it/s, loss=0.622]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.69it/s]\n",
      "epoch 1: trn_loss = 0.6225, val_loss = 0.1168, trn_score = 1.3983, val_score = 0.4844\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 195/195 [02:14<00:00,  1.45it/s, loss=0.111]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 2: trn_loss = 0.1109, val_loss = 0.1057, trn_score = 0.4721, val_score = 0.4600\n",
      "model (best score) saved\n",
      "lr :  [5.051616592567323e-06, 5.051616592567323e-06, 5.051616592567323e-05]\n",
      "100%|█████████████████████████████| 195/195 [02:15<00:00,  1.44it/s, loss=0.107]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.60it/s]\n",
      "epoch 3: trn_loss = 0.1072, val_loss = 0.1043, trn_score = 0.4639, val_score = 0.4569\n",
      "model (best score) saved\n",
      "lr :  [2.442504256457412e-06, 2.442504256457412e-06, 2.442504256457412e-05]\n",
      "100%|█████████████████████████████| 195/195 [02:15<00:00,  1.44it/s, loss=0.101]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 4: trn_loss = 0.1009, val_loss = 0.1051, trn_score = 0.4499, val_score = 0.4587\n",
      "lr :  [6.943712673948621e-07, 6.943712673948621e-07, 6.943712673948622e-06]\n",
      "100%|█████████████████████████████| 195/195 [02:15<00:00,  1.44it/s, loss=0.099]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 5: trn_loss = 0.0990, val_loss = 0.1038, trn_score = 0.4457, val_score = 0.4558\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 5e-5 \n",
    "HEAD_LR = 5e-5\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16\n",
    "CP = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 21:28:38.579428: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 21:28:38.579453: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:35<00:00,  2.05it/s, loss=0.573]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:19<00:00,  2.58it/s]\n",
      "epoch 1: trn_loss = 0.5729, val_loss = 0.1130, trn_score = 1.3310, val_score = 0.4763\n",
      "model (best score) saved\n",
      "lr :  [2.0561170093642423e-05, 2.0561170093642423e-05, 2.0561170093642423e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:39<00:00,  1.97it/s, loss=0.112]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.61it/s]\n",
      "epoch 2: trn_loss = 0.1118, val_loss = 0.1079, trn_score = 0.4741, val_score = 0.4646\n",
      "model (best score) saved\n",
      "lr :  [1.2629041481418307e-05, 1.2629041481418307e-05, 1.2629041481418307e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  1.99it/s, loss=0.111]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 3: trn_loss = 0.1107, val_loss = 0.1043, trn_score = 0.4717, val_score = 0.4569\n",
      "model (best score) saved\n",
      "lr :  [6.10626064114353e-06, 6.10626064114353e-06, 6.10626064114353e-06]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.104]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.67it/s]\n",
      "epoch 4: trn_loss = 0.1038, val_loss = 0.1051, trn_score = 0.4565, val_score = 0.4589\n",
      "lr :  [1.7359281684871554e-06, 1.7359281684871554e-06, 1.7359281684871554e-06]\n",
      "100%|████████████████████████████| 195/195 [01:37<00:00,  2.00it/s, loss=0.0994]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 5: trn_loss = 0.0994, val_loss = 0.1034, trn_score = 0.4466, val_score = 0.4552\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 5e-5 \n",
    "HEAD_LR = 5e-5\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16\n",
    "CP = 'false'\n",
    "WD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 21:40:17.297621: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 21:40:17.297646: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:34<00:00,  2.05it/s, loss=0.575]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.65it/s]\n",
      "epoch 1: trn_loss = 0.5754, val_loss = 0.1112, trn_score = 1.3342, val_score = 0.4722\n",
      "model (best score) saved\n",
      "lr :  [2.0561170093642423e-05, 2.0561170093642423e-05, 2.0561170093642423e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.01it/s, loss=0.111]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 2: trn_loss = 0.1110, val_loss = 0.1051, trn_score = 0.4723, val_score = 0.4588\n",
      "model (best score) saved\n",
      "lr :  [1.2629041481418307e-05, 1.2629041481418307e-05, 1.2629041481418307e-05]\n",
      "100%|██████████████████████████████| 195/195 [01:37<00:00,  2.00it/s, loss=0.11]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 3: trn_loss = 0.1097, val_loss = 0.1034, trn_score = 0.4696, val_score = 0.4551\n",
      "model (best score) saved\n",
      "lr :  [6.10626064114353e-06, 6.10626064114353e-06, 6.10626064114353e-06]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.01it/s, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 4: trn_loss = 0.1032, val_loss = 0.1048, trn_score = 0.4551, val_score = 0.4581\n",
      "lr :  [1.7359281684871554e-06, 1.7359281684871554e-06, 1.7359281684871554e-06]\n",
      "100%|████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.0994]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 5: trn_loss = 0.0994, val_loss = 0.1032, trn_score = 0.4466, val_score = 0.4548\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 21:51:14.906598: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 21:51:14.906621: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:35<00:00,  2.04it/s, loss=0.548]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 1: trn_loss = 0.5483, val_loss = 0.1293, trn_score = 1.3048, val_score = 0.5105\n",
      "model (best score) saved\n",
      "lr :  [4.848552474397676e-05, 4.848552474397676e-05, 4.848552474397676e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.01it/s, loss=0.116]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 2: trn_loss = 0.1165, val_loss = 0.1066, trn_score = 0.4842, val_score = 0.4622\n",
      "model (best score) saved\n",
      "lr :  [3.752575533885138e-05, 3.752575533885138e-05, 3.752575533885138e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.01it/s, loss=0.101]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 3: trn_loss = 0.1011, val_loss = 0.1111, trn_score = 0.4502, val_score = 0.4719\n",
      "lr :  [2.0736945184184405e-05, 2.0736945184184405e-05, 2.0736945184184405e-05]\n",
      "100%|████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.0912]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 4: trn_loss = 0.0912, val_loss = 0.1046, trn_score = 0.4275, val_score = 0.4580\n",
      "model (best score) saved\n",
      "lr :  [5.932009020880045e-06, 5.932009020880045e-06, 5.932009020880045e-06]\n",
      "100%|████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.0847]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 5: trn_loss = 0.0847, val_loss = 0.1038, trn_score = 0.4118, val_score = 0.4561\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 5e-5 \n",
    "HEAD_LR = 5e-5\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16\n",
    "CP = 'false'\n",
    "WD = 1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 22:06:22.601043: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 22:06:22.601066: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:34<00:00,  2.06it/s, loss=0.623]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.66it/s]\n",
      "epoch 1: trn_loss = 0.6234, val_loss = 0.1106, trn_score = 1.3990, val_score = 0.4710\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.112]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.61it/s]\n",
      "epoch 2: trn_loss = 0.1117, val_loss = 0.1076, trn_score = 0.4738, val_score = 0.4640\n",
      "model (best score) saved\n",
      "lr :  [5.051616592567323e-06, 5.051616592567323e-06, 5.051616592567323e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.00it/s, loss=0.107]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.61it/s]\n",
      "epoch 3: trn_loss = 0.1068, val_loss = 0.1043, trn_score = 0.4631, val_score = 0.4568\n",
      "model (best score) saved\n",
      "lr :  [2.442504256457412e-06, 2.442504256457412e-06, 2.442504256457412e-05]\n",
      "100%|███████████████████████████████| 195/195 [01:37<00:00,  1.99it/s, loss=0.1]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 4: trn_loss = 0.1002, val_loss = 0.1046, trn_score = 0.4485, val_score = 0.4576\n",
      "lr :  [6.943712673948621e-07, 6.943712673948621e-07, 6.943712673948622e-06]\n",
      "100%|████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.0983]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 5: trn_loss = 0.0983, val_loss = 0.1033, trn_score = 0.4441, val_score = 0.4549\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 2e-5 \n",
    "HEAD_LR = 2e-4\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16\n",
    "CP = 'false'\n",
    "WD = 1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 22:17:31.811384: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 22:17:31.811440: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:35<00:00,  2.04it/s, loss=0.625]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 1: trn_loss = 0.6249, val_loss = 0.1107, trn_score = 1.4026, val_score = 0.4708\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.01it/s, loss=0.111]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 2: trn_loss = 0.1106, val_loss = 0.1119, trn_score = 0.4715, val_score = 0.4734\n",
      "lr :  [5.051616592567323e-06, 5.051616592567323e-06, 5.051616592567323e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.01it/s, loss=0.107]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.65it/s]\n",
      "epoch 3: trn_loss = 0.1069, val_loss = 0.1058, trn_score = 0.4634, val_score = 0.4601\n",
      "model (best score) saved\n",
      "lr :  [2.442504256457412e-06, 2.442504256457412e-06, 2.442504256457412e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 4: trn_loss = 0.1026, val_loss = 0.1072, trn_score = 0.4539, val_score = 0.4631\n",
      "lr :  [6.943712673948621e-07, 6.943712673948621e-07, 6.943712673948622e-06]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.101]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 5: trn_loss = 0.1007, val_loss = 0.1044, trn_score = 0.4495, val_score = 0.4572\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 2e-5 \n",
    "HEAD_LR = 2e-4\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16\n",
    "CP = 'false'\n",
    "WD = 0.1 #1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 22:31:09.341577: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 22:31:09.341623: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:34<00:00,  2.06it/s, loss=0.455]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.66it/s]\n",
      "epoch 1: trn_loss = 0.4546, val_loss = 0.1115, trn_score = 1.1688, val_score = 0.4732\n",
      "model (best score) saved\n",
      "lr :  [4.1122340187284846e-05, 4.1122340187284846e-05, 4.1122340187284846e-05]\n",
      "100%|██████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.11]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 2: trn_loss = 0.1101, val_loss = 0.1048, trn_score = 0.4704, val_score = 0.4581\n",
      "model (best score) saved\n",
      "lr :  [2.5258082962836614e-05, 2.5258082962836614e-05, 2.5258082962836614e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.01it/s, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 3: trn_loss = 0.1083, val_loss = 0.1033, trn_score = 0.4666, val_score = 0.4548\n",
      "model (best score) saved\n",
      "lr :  [1.221252128228706e-05, 1.221252128228706e-05, 1.221252128228706e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 4: trn_loss = 0.1033, val_loss = 0.1056, trn_score = 0.4558, val_score = 0.4602\n",
      "lr :  [3.471856336974311e-06, 3.471856336974311e-06, 3.471856336974311e-06]\n",
      "100%|████████████████████████████| 195/195 [01:37<00:00,  2.01it/s, loss=0.0959]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 5: trn_loss = 0.0959, val_loss = 0.1036, trn_score = 0.4387, val_score = 0.4557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-4 \n",
    "HEAD_LR = 1e-4\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16\n",
    "CP = 'false'\n",
    "WD = 1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 22:43:13.265175: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 22:43:13.265200: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|███████████████████████████████| 97/97 [02:06<00:00,  1.31s/it, loss=0.606]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.50it/s]\n",
      "epoch 1: trn_loss = 0.6062, val_loss = 0.1150, trn_score = 1.3716, val_score = 0.4802\n",
      "model (best score) saved\n",
      "lr :  [4.1122340187284846e-05, 4.1122340187284846e-05, 4.1122340187284846e-05]\n",
      "100%|███████████████████████████████| 97/97 [02:08<00:00,  1.32s/it, loss=0.118]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.50it/s]\n",
      "epoch 2: trn_loss = 0.1178, val_loss = 0.1106, trn_score = 0.4868, val_score = 0.4708\n",
      "model (best score) saved\n",
      "lr :  [2.6037550663997157e-05, 2.6037550663997157e-05, 2.6037550663997157e-05]\n",
      "100%|███████████████████████████████| 97/97 [02:07<00:00,  1.31s/it, loss=0.111]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.51it/s]\n",
      "epoch 3: trn_loss = 0.1106, val_loss = 0.1075, trn_score = 0.4715, val_score = 0.4638\n",
      "model (best score) saved\n",
      "lr :  [1.340527389091374e-05, 1.340527389091374e-05, 1.340527389091374e-05]\n",
      "100%|████████████████████████████████| 97/97 [02:07<00:00,  1.31s/it, loss=0.11]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.50it/s]\n",
      "epoch 4: trn_loss = 0.1101, val_loss = 0.1085, trn_score = 0.4709, val_score = 0.4664\n",
      "lr :  [4.518400232274106e-06, 4.518400232274106e-06, 4.518400232274106e-06]\n",
      "100%|█████████████████████████████████| 97/97 [02:06<00:00,  1.31s/it, loss=0.1]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:16<00:00,  1.51it/s]\n",
      "epoch 5: trn_loss = 0.1000, val_loss = 0.1043, trn_score = 0.4478, val_score = 0.4572\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-4 \n",
    "HEAD_LR = 1e-4\n",
    "SEED = 100\n",
    "TRN_BS = 32#16\n",
    "VAL_BS = 32 #16 \n",
    "CP = 'true' #'false'\n",
    "WD = 1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 22:59:26.497016: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 22:59:26.497037: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1173\n",
      "num_warmup_steps =  117\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:34<00:00,  2.06it/s, loss=0.616]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.67it/s]\n",
      "epoch 1: trn_loss = 0.6157, val_loss = 0.1288, trn_score = 1.3852, val_score = 0.5098\n",
      "model (best score) saved\n",
      "lr :  [2.943882990635758e-05, 2.943882990635758e-05, 2.943882990635758e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.114]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 2: trn_loss = 0.1144, val_loss = 0.1110, trn_score = 0.4801, val_score = 0.4714\n",
      "model (best score) saved\n",
      "lr :  [2.1001012504603484e-05, 2.1001012504603484e-05, 2.1001012504603484e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.01it/s, loss=0.105]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 3: trn_loss = 0.1046, val_loss = 0.1070, trn_score = 0.4583, val_score = 0.4629\n",
      "model (best score) saved\n",
      "lr :  [1.3018775331998578e-05, 1.3018775331998578e-05, 1.3018775331998578e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.01it/s, loss=0.101]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 4: trn_loss = 0.1007, val_loss = 0.1068, trn_score = 0.4496, val_score = 0.4628\n",
      "model (best score) saved\n",
      "lr :  [6.401485933303791e-06, 6.401485933303791e-06, 6.401485933303791e-06]\n",
      "100%|████████████████████████████| 195/195 [01:36<00:00,  2.02it/s, loss=0.0949]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 5: trn_loss = 0.0949, val_loss = 0.1036, trn_score = 0.4361, val_score = 0.4557\n",
      "model (best score) saved\n",
      "lr :  [1.9030116872178316e-06, 1.9030116872178316e-06, 1.9030116872178316e-06]\n",
      "100%|████████████████████████████| 195/195 [01:36<00:00,  2.03it/s, loss=0.0886]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 6: trn_loss = 0.0886, val_loss = 0.1032, trn_score = 0.4214, val_score = 0.4546\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 5e-5 \n",
    "HEAD_LR = 5e-5\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16 \n",
    "CP = 'false'\n",
    "WD = 1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 6 #5\n",
    "STOP_EPOCH = 6 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 23:12:40.624912: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 23:12:40.624934: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [01:35<00:00,  2.04it/s, loss=0.569]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 1: trn_loss = 0.5689, val_loss = 0.1100, trn_score = 1.3265, val_score = 0.4694\n",
      "model (best score) saved\n",
      "lr :  [2.0561170093642423e-05, 2.0561170093642423e-05, 2.0561170093642423e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.00it/s, loss=0.111]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.61it/s]\n",
      "epoch 2: trn_loss = 0.1113, val_loss = 0.1054, trn_score = 0.4731, val_score = 0.4593\n",
      "model (best score) saved\n",
      "lr :  [1.2629041481418307e-05, 1.2629041481418307e-05, 1.2629041481418307e-05]\n",
      "100%|█████████████████████████████| 195/195 [01:37<00:00,  2.00it/s, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 3: trn_loss = 0.1081, val_loss = 0.1037, trn_score = 0.4660, val_score = 0.4555\n",
      "model (best score) saved\n",
      "lr :  [6.10626064114353e-06, 6.10626064114353e-06, 6.10626064114353e-06]\n",
      "100%|█████████████████████████████| 195/195 [01:36<00:00,  2.01it/s, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 4: trn_loss = 0.1031, val_loss = 0.1042, trn_score = 0.4551, val_score = 0.4567\n",
      "lr :  [1.7359281684871554e-06, 1.7359281684871554e-06, 1.7359281684871554e-06]\n",
      "100%|████████████████████████████| 195/195 [01:36<00:00,  2.01it/s, loss=0.0993]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 5: trn_loss = 0.0993, val_loss = 0.1031, trn_score = 0.4462, val_score = 0.4545\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 5e-5 \n",
    "HEAD_LR = 5e-5\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16 \n",
    "CP = 'false'\n",
    "WD = 10 #1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 23:30:17.704505: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 23:30:17.704528: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  977\n",
      "num_warmup_steps =  97\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [03:16<00:00,  1.01s/it, loss=0.785]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 1: trn_loss = 0.7845, val_loss = 0.1121, trn_score = 1.0695, val_score = 0.4744\n",
      "model (best score) saved\n",
      "lr :  [2.0561170093642423e-05, 2.0561170093642423e-05, 2.0561170093642423e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:18<00:00,  1.02s/it, loss=0.222]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 2: trn_loss = 0.2219, val_loss = 0.1084, trn_score = 0.4697, val_score = 0.4662\n",
      "model (best score) saved\n",
      "lr :  [1.2629041481418307e-05, 1.2629041481418307e-05, 1.2629041481418307e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:17<00:00,  1.01s/it, loss=0.197]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.66it/s]\n",
      "epoch 3: trn_loss = 0.1966, val_loss = 0.1055, trn_score = 0.4415, val_score = 0.4598\n",
      "model (best score) saved\n",
      "lr :  [6.10626064114353e-06, 6.10626064114353e-06, 6.10626064114353e-06]\n",
      "100%|█████████████████████████████| 195/195 [03:16<00:00,  1.01s/it, loss=0.179]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.65it/s]\n",
      "epoch 4: trn_loss = 0.1789, val_loss = 0.1081, trn_score = 0.4207, val_score = 0.4659\n",
      "lr :  [1.7359281684871554e-06, 1.7359281684871554e-06, 1.7359281684871554e-06]\n",
      "100%|█████████████████████████████| 195/195 [03:15<00:00,  1.00s/it, loss=0.158]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.65it/s]\n",
      "epoch 5: trn_loss = 0.1576, val_loss = 0.1071, trn_score = 0.3946, val_score = 0.4634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 5e-5 \n",
    "HEAD_LR = 5e-5\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16 \n",
    "CP = 'false'\n",
    "WD = 10 #1\n",
    "\n",
    "AWP = 'true'\n",
    "AWP_LR = 2e-4\n",
    "AWP_EPS = 1e-3\n",
    "AWP_START_EPOCH = -1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-09 23:48:34.400637: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-09 23:48:34.400686: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 195/195 [03:15<00:00,  1.00s/it, loss=0.987]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:17<00:00,  2.72it/s]\n",
      "epoch 1: trn_loss = 0.9873, val_loss = 0.1308, trn_score = 1.2170, val_score = 0.5142\n",
      "model (best score) saved\n",
      "lr :  [5e-05, 5e-05, 5e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:13<00:00,  1.01it/s, loss=0.229]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.71it/s]\n",
      "epoch 2: trn_loss = 0.2290, val_loss = 0.1117, trn_score = 0.4773, val_score = 0.4733\n",
      "model (best score) saved\n",
      "lr :  [4.857595131994781e-05, 4.857595131994781e-05, 4.857595131994781e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:14<00:00,  1.00it/s, loss=0.211]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.66it/s]\n",
      "epoch 3: trn_loss = 0.2112, val_loss = 0.1117, trn_score = 0.4579, val_score = 0.4735\n",
      "lr :  [4.446603845124389e-05, 4.446603845124389e-05, 4.446603845124389e-05]\n",
      "100%|██████████████████████████████| 195/195 [03:16<00:00,  1.01s/it, loss=0.19]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.64it/s]\n",
      "epoch 4: trn_loss = 0.1901, val_loss = 0.1185, trn_score = 0.4337, val_score = 0.4877\n",
      "lr :  [3.81384786735528e-05, 3.81384786735528e-05, 3.81384786735528e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:16<00:00,  1.01s/it, loss=0.162]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 5: trn_loss = 0.1621, val_loss = 0.1105, trn_score = 0.4002, val_score = 0.4710\n",
      "model (best score) saved\n",
      "lr :  [3.0314132238824432e-05, 3.0314132238824432e-05, 3.0314132238824432e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:16<00:00,  1.01s/it, loss=0.144]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 6: trn_loss = 0.1437, val_loss = 0.1125, trn_score = 0.3764, val_score = 0.4754\n",
      "lr :  [2.1884379164070403e-05, 2.1884379164070403e-05, 2.1884379164070403e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:16<00:00,  1.01s/it, loss=0.126]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 7: trn_loss = 0.1263, val_loss = 0.1099, trn_score = 0.3529, val_score = 0.4700\n",
      "model (best score) saved\n",
      "lr :  [1.3809569748432138e-05, 1.3809569748432138e-05, 1.3809569748432138e-05]\n",
      "100%|█████████████████████████████| 195/195 [03:16<00:00,  1.01s/it, loss=0.115]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.62it/s]\n",
      "epoch 8: trn_loss = 0.1146, val_loss = 0.1114, trn_score = 0.3364, val_score = 0.4733\n",
      "lr :  [7.0096177271109675e-06, 7.0096177271109675e-06, 7.0096177271109675e-06]\n",
      "100%|█████████████████████████████| 195/195 [03:15<00:00,  1.00s/it, loss=0.106]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 9: trn_loss = 0.1062, val_loss = 0.1101, trn_score = 0.3236, val_score = 0.4702\n",
      "lr :  [2.259200116137053e-06, 2.259200116137053e-06, 2.259200116137053e-06]\n",
      "100%|████████████████████████████| 195/195 [03:15<00:00,  1.00s/it, loss=0.0976]\n",
      "100%|███████████████████████████████████████████| 49/49 [00:18<00:00,  2.63it/s]\n",
      "epoch 10: trn_loss = 0.0976, val_loss = 0.1113, trn_score = 0.3104, val_score = 0.4730\n",
      " elapsed_time = 35.8 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 5e-5 \n",
    "HEAD_LR = 5e-5\n",
    "SEED = 100\n",
    "TRN_BS = 16\n",
    "VAL_BS = 16 \n",
    "CP = 'false'\n",
    "WD = 10 #1\n",
    "\n",
    "AWP = 'true'\n",
    "AWP_LR = 2e-4\n",
    "AWP_EPS = 1e-3\n",
    "AWP_START_EPOCH = -1\n",
    "\n",
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 1\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 2\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 3\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 4\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "MODE = 'train'\n",
    "EPOCHS = 5\n",
    "STOP_EPOCH = 5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = EPOCHS\n",
    "PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "--accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "--mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "--msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "--eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "--mt $MULTI_TASK --w_mt $W_MT \\\n",
    "--awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "--pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "--gradient_clip_val $GRAD_CLIP \\\n",
    "--input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "--crop_prob $CROP_PROB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}.pth'\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "--fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "--window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for FOLD in [1,2,3,4]:\n",
    "    WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}.pth'\n",
    "    !python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "    --fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "    --rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "    --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_fold = 5\n",
    "\n",
    "preds = []\n",
    "for fold in range(num_fold):\n",
    "    tmp_df = pd.read_csv(f'./result/{VERSION}/pred_fold{fold}.csv')\n",
    "    embeds = np.load(f'./result/{VERSION}/embeds_fold{fold}.npz')['arr_0']\n",
    "    tmp_df['embed'] = embeds.tolist()\n",
    "    preds.append(tmp_df)\n",
    "    \n",
    "pred_df = pd.concat(preds, axis=0).reset_index(drop=True)\n",
    "train_df = pd.read_csv('../../input/feedback-prize-english-language-learning/train.csv')\n",
    "\n",
    "oof_df = train_df[['text_id']].merge(pred_df, on='text_id', how='left')\n",
    "oof_df.to_csv(f'./result/{VERSION}/oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.shape, oof_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
