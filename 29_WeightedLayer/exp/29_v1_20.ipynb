{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '29_v1_20'\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "#'deepset/deberta-v3-base-squad2'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#TEACHER_VERSION = '14_v1_15' # deverta-v2-xlarge\n",
    "#'bert-large-cased'\n",
    "#'bert-large-cased-whole-word-masking'\n",
    "#'albert-large-v2'\n",
    "#'facebook/bart-large'\n",
    "#'xlm-roberta-large'\n",
    "#'deepset/roberta-large-squad2'\n",
    "#'google/electra-large-discriminator'\n",
    "#'sentence-transformeres/paraphrase-mpnet-base-v2'\n",
    "#'funnel-transformer/large-base'\n",
    "#'facebook/bart-base'\n",
    "#'distilroberta-base'\n",
    "#'deepset/roberta-base-squad2'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'roberta-large'\n",
    "#'roberta-base'\n",
    "#'microsoft/deberta-v3-large'\n",
    "#'microsoft/deberta-base'\n",
    "LR = 8e-5 #8e-6\n",
    "HEAD_LR = 8e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 64 #8\n",
    "VAL_BS = 64 #8\n",
    "ACCUM_STEP = 1\n",
    "HIDDEN_DROP_PROB = 0\n",
    "P_DROP = 0\n",
    "RNN = 'none'\n",
    "WARMUP_RATIO = 0.1\n",
    "HEAD = 'simple'\n",
    "AUG = 'false'\n",
    "MIXUP_ALPHA = 0\n",
    "P_AUG = 0\n",
    "AUG_STOP_EPOCH = 0\n",
    "MSD = 'false'\n",
    "POOLING = 'weighted_layer'  #'mean' #'transformer+mean' #'attention'\n",
    "NUM_POOLING_LAYERS = 4 #1\n",
    "MULTI_LAYERS = 1\n",
    "EVAL_STEP_START_EPOCH = -1\n",
    "EVAL_STEP = -1\n",
    "NUM_LABELS = 6\n",
    "NUM_LABELS_2 = -1\n",
    "FP16 = 'true'\n",
    "WD = 0.01\n",
    "FREEZE = 'false'\n",
    "MULTI_TASK = 'false' \n",
    "W_MT = 0 \n",
    "AWP = 'true' #'false'\n",
    "AWP_LR = 1e-3\n",
    "AWP_EPS = 1e-3\n",
    "AWP_START_EPOCH = 5\n",
    "#PRETRAINED_DETECTOR_PATH = f'../../input/tascj/result/deberta_base_fold0.pth'\n",
    "PRETRAINED_DETECTOR_PATH = 'none' #f'../../05_Detection/exp/result/05_v2_09/model_seed100_fold0_swa.pth'\n",
    "MASK_PROB = 0 #0.8\n",
    "MASK_RATIO = 0 #0.3\n",
    "SCHEDULER = 'cosine_hard'\n",
    "CP = 'true' #'false'\n",
    "WINDOW_SIZE = -1\n",
    "INNER_LEN = -1\n",
    "EDGE_LEN = -1\n",
    "MAX_LEN = 512\n",
    "\n",
    "GRAD_CLIP = 1\n",
    "\n",
    "LOSS = 'smoothl1'#'mse'\n",
    "\n",
    "CROP_PROB = 0 #1.0\n",
    "\n",
    "USE_STATS = 'false' #'true'\n",
    "USE_SEPARATE_HEAD = 'true'\n",
    "\n",
    "LOW_LOSS_THR = -1 #0.8 #0.5\n",
    "HIGH_LOSS_THR = -1 #0.0001\n",
    "OOF_DF_PATH = 'none' #'../../14_Baseline4/exp/result/14_v1_01/oof_df.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "2022-11-24 09:14:50.530769: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-24 09:14:50.530790: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████████| 48/48 [02:03<00:00,  2.57s/it, loss=1.1]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:15<00:00,  1.22s/it]\n",
      "epoch 1: trn_loss = 1.1017, val_loss = 0.1300, trn_score = 1.9774, val_score = 0.5117\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [02:04<00:00,  2.60s/it, loss=0.123]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.27s/it]\n",
      "epoch 2: trn_loss = 0.1227, val_loss = 0.1126, trn_score = 0.4975, val_score = 0.4756\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [02:05<00:00,  2.62s/it, loss=0.113]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 3: trn_loss = 0.1129, val_loss = 0.1067, trn_score = 0.4764, val_score = 0.4621\n",
      "model (best score) saved\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [02:05<00:00,  2.61s/it, loss=0.102]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 4: trn_loss = 0.1017, val_loss = 0.1192, trn_score = 0.4519, val_score = 0.4904\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|███████████████████████████████| 48/48 [04:10<00:00,  5.22s/it, loss=0.349]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.25s/it]\n",
      "epoch 5: trn_loss = 0.3487, val_loss = 0.1099, trn_score = 0.6094, val_score = 0.4698\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|███████████████████████████████| 48/48 [04:10<00:00,  5.22s/it, loss=0.196]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 6: trn_loss = 0.1956, val_loss = 0.1100, trn_score = 0.4406, val_score = 0.4699\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|███████████████████████████████| 48/48 [04:10<00:00,  5.22s/it, loss=0.177]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 7: trn_loss = 0.1765, val_loss = 0.1073, trn_score = 0.4177, val_score = 0.4639\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|███████████████████████████████| 48/48 [04:10<00:00,  5.22s/it, loss=0.156]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 8: trn_loss = 0.1562, val_loss = 0.1078, trn_score = 0.3930, val_score = 0.4653\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.25s/it, loss=0.146]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.27s/it]\n",
      "epoch 9: trn_loss = 0.1459, val_loss = 0.1063, trn_score = 0.3796, val_score = 0.4617\n",
      "model (best score) saved\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|███████████████████████████████| 48/48 [04:10<00:00,  5.23s/it, loss=0.141]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 10: trn_loss = 0.1406, val_loss = 0.1055, trn_score = 0.3728, val_score = 0.4601\n",
      " elapsed_time = 36.2 min\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0]: #[0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "2022-11-24 09:52:43.619873: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-24 09:52:43.619894: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 48/48 [02:05<00:00,  2.61s/it, loss=1.13]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.28s/it]\n",
      "epoch 1: trn_loss = 1.1301, val_loss = 0.1355, trn_score = 1.9996, val_score = 0.5230\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [02:06<00:00,  2.63s/it, loss=0.121]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 2: trn_loss = 0.1212, val_loss = 0.1214, trn_score = 0.4946, val_score = 0.4936\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [02:05<00:00,  2.62s/it, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 3: trn_loss = 0.1081, val_loss = 0.1054, trn_score = 0.4661, val_score = 0.4593\n",
      "model (best score) saved\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [02:05<00:00,  2.62s/it, loss=0.102]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 4: trn_loss = 0.1025, val_loss = 0.1158, trn_score = 0.4537, val_score = 0.4826\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.23s/it, loss=0.369]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 5: trn_loss = 0.3686, val_loss = 0.1108, trn_score = 0.6366, val_score = 0.4715\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.23s/it, loss=0.195]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 6: trn_loss = 0.1954, val_loss = 0.1114, trn_score = 0.4416, val_score = 0.4728\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.23s/it, loss=0.174]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 7: trn_loss = 0.1738, val_loss = 0.1055, trn_score = 0.4159, val_score = 0.4601\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.24s/it, loss=0.153]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 8: trn_loss = 0.1533, val_loss = 0.1089, trn_score = 0.3903, val_score = 0.4676\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.24s/it, loss=0.142]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 9: trn_loss = 0.1417, val_loss = 0.1070, trn_score = 0.3754, val_score = 0.4635\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.24s/it, loss=0.136]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.27s/it]\n",
      "epoch 10: trn_loss = 0.1357, val_loss = 0.1067, trn_score = 0.3673, val_score = 0.4627\n",
      " elapsed_time = 36.3 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AWP = 'true' #'false'\n",
    "AWP_LR = 1e-4 #1e-3\n",
    "AWP_EPS = 1e-3\n",
    "AWP_START_EPOCH = 5\n",
    "\n",
    "\n",
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0]: #[0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "2022-11-24 12:20:12.426120: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-24 12:20:12.426143: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████████| 48/48 [02:03<00:00,  2.57s/it, loss=1.1]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.23s/it]\n",
      "epoch 1: trn_loss = 1.1045, val_loss = 0.1330, trn_score = 1.9766, val_score = 0.5175\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [04:12<00:00,  5.25s/it, loss=0.372]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 2: trn_loss = 0.3719, val_loss = 0.1208, trn_score = 0.6258, val_score = 0.4924\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.23s/it, loss=0.207]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.27s/it]\n",
      "epoch 3: trn_loss = 0.2074, val_loss = 0.1238, trn_score = 0.4561, val_score = 0.4991\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.23s/it, loss=0.176]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.27s/it]\n",
      "epoch 4: trn_loss = 0.1759, val_loss = 0.1076, trn_score = 0.4197, val_score = 0.4643\n",
      "model (best score) saved\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.23s/it, loss=0.139]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 5: trn_loss = 0.1395, val_loss = 0.1089, trn_score = 0.3735, val_score = 0.4672\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|███████████████████████████████| 48/48 [04:11<00:00,  5.24s/it, loss=0.111]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.27s/it]\n",
      "epoch 6: trn_loss = 0.1111, val_loss = 0.1066, trn_score = 0.3331, val_score = 0.4622\n",
      "model (best score) saved\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|██████████████████████████████| 48/48 [04:11<00:00,  5.24s/it, loss=0.0962]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 7: trn_loss = 0.0962, val_loss = 0.1102, trn_score = 0.3097, val_score = 0.4700\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|██████████████████████████████| 48/48 [04:11<00:00,  5.24s/it, loss=0.0871]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.27s/it]\n",
      "epoch 8: trn_loss = 0.0871, val_loss = 0.1113, trn_score = 0.2948, val_score = 0.4728\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|██████████████████████████████| 48/48 [04:11<00:00,  5.25s/it, loss=0.0808]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 9: trn_loss = 0.0808, val_loss = 0.1112, trn_score = 0.2837, val_score = 0.4723\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|██████████████████████████████| 48/48 [04:11<00:00,  5.24s/it, loss=0.0787]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:16<00:00,  1.26s/it]\n",
      "epoch 10: trn_loss = 0.0787, val_loss = 0.1110, trn_score = 0.2800, val_score = 0.4718\n",
      " elapsed_time = 42.6 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AWP = 'true' #'false'\n",
    "AWP_LR = 1e-5 #1e-4 #1e-3\n",
    "AWP_EPS = 1e-5 #1e-3\n",
    "AWP_START_EPOCH = 2\n",
    "\n",
    "\n",
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0]: #[0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "# FOLD_PATH = '../../00_EDA/00_v1_02/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}.pth'\n",
    "        #WEIGHT_PATH = f'./result/{VERSION}/model_{CLASS}_seed{SEED}_fold{FOLD}.pth'\n",
    "        #WEIGHT_PATH = f'result/{VERSION}/model_{CLASS}_seed{SEED}_fold{FOLD}_pseudo.pth'\n",
    "        !python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "        --fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "        --rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN \\\n",
    "        --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS \\\n",
    "        --class_name $CLASS --input_path $INPUT_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "preds = []\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "#     preds_class = []\n",
    "if True:\n",
    "    for fold in [0,1,2,3,4]:\n",
    "        tmp_df = pd.read_csv(f'./result/{VERSION}/pred_fold{fold}.csv')\n",
    "        #tmp_df = pd.read_csv(f'./result/{VERSION}/pred_{CLASS}_fold{fold}.csv')\n",
    "        #embeds = np.load(f'./result/{VERSION}/embeds_{CLASS}_fold{fold}.npz')['arr_0']\n",
    "        #tmp_df[f'embed_{CLASS}'] = embeds.tolist()\n",
    "        #preds_class.append(tmp_df)\n",
    "        preds.append(tmp_df)\n",
    "#     pred_df = pd.concat(preds_class, axis=0).reset_index(drop=True)\n",
    "#     if len(preds)==0:\n",
    "#         preds.append(pred_df)\n",
    "#     else:\n",
    "#         del pred_df[\"text_id\"]\n",
    "#         preds.append(pred_df)\n",
    "    \n",
    "#all_pred_df = pd.concat(preds, axis=1)\n",
    "all_pred_df = pd.concat(preds, axis=0).reset_index(drop=True)\n",
    "\n",
    "train_df = pd.read_csv('../../input/feedback-prize-english-language-learning/train.csv')\n",
    "oof_df = train_df[['text_id']].merge(all_pred_df, on='text_id', how='left')\n",
    "oof_df.to_csv(f'./result/{VERSION}/oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.shape, oof_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis - Check Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
