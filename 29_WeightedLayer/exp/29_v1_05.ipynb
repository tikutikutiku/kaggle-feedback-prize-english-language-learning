{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '29_v1_05'\n",
    "MODEL = 'xlm-roberta-base'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#TEACHER_VERSION = '14_v1_15' # deverta-v2-xlarge\n",
    "#'bert-large-cased'\n",
    "#'bert-large-cased-whole-word-masking'\n",
    "#'albert-large-v2'\n",
    "#'facebook/bart-large'\n",
    "#'xlm-roberta-large'\n",
    "#'deepset/roberta-large-squad2'\n",
    "#'google/electra-large-discriminator'\n",
    "#'sentence-transformeres/paraphrase-mpnet-base-v2'\n",
    "#'funnel-transformer/large-base'\n",
    "#'facebook/bart-base'\n",
    "#'distilroberta-base'\n",
    "#'deepset/roberta-base-squad2'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'roberta-large'\n",
    "#'roberta-base'\n",
    "#'microsoft/deberta-v3-large'\n",
    "#'microsoft/deberta-base'\n",
    "# LR = 2e-5 #8e-6\n",
    "# HEAD_LR = 2e-4 #2e-5 #8e-6 \n",
    "# SEED = 100\n",
    "# TRN_BS = 64 #8\n",
    "# VAL_BS = 64 #8\n",
    "ACCUM_STEP = 1\n",
    "HIDDEN_DROP_PROB = 0\n",
    "P_DROP = 0\n",
    "RNN = 'none'\n",
    "WARMUP_RATIO = 0.1\n",
    "HEAD = 'simple'\n",
    "AUG = 'false'\n",
    "MIXUP_ALPHA = 0\n",
    "P_AUG = 0\n",
    "AUG_STOP_EPOCH = 0\n",
    "MSD = 'false'\n",
    "POOLING = 'weighted_layer'  #'mean' #'transformer+mean' #'attention'\n",
    "NUM_POOLING_LAYERS = 4 #1\n",
    "MULTI_LAYERS = 1\n",
    "EVAL_STEP_START_EPOCH = -1\n",
    "EVAL_STEP = -1\n",
    "NUM_LABELS = 6\n",
    "NUM_LABELS_2 = -1\n",
    "FP16 = 'true'\n",
    "WD = 0.01\n",
    "FREEZE = 'false'\n",
    "MULTI_TASK = 'false' \n",
    "W_MT = 0 \n",
    "AWP = 'false'\n",
    "AWP_LR = 0\n",
    "AWP_EPS = 0\n",
    "AWP_START_EPOCH = -1\n",
    "#PRETRAINED_DETECTOR_PATH = f'../../input/tascj/result/deberta_base_fold0.pth'\n",
    "PRETRAINED_DETECTOR_PATH = 'none' #f'../../05_Detection/exp/result/05_v2_09/model_seed100_fold0_swa.pth'\n",
    "MASK_PROB = 0 #0.8\n",
    "MASK_RATIO = 0 #0.3\n",
    "SCHEDULER = 'cosine_hard'\n",
    "CP = 'true' #'false'\n",
    "WINDOW_SIZE = -1\n",
    "INNER_LEN = -1\n",
    "EDGE_LEN = -1\n",
    "MAX_LEN = 512\n",
    "\n",
    "GRAD_CLIP = 1\n",
    "\n",
    "LOSS = 'smoothl1'#'mse'\n",
    "\n",
    "CROP_PROB = 0 #1.0\n",
    "\n",
    "USE_STATS = 'false' #'true'\n",
    "USE_SEPARATE_HEAD = 'true'\n",
    "\n",
    "LOW_LOSS_THR = -1 #0.8 #0.5\n",
    "HIGH_LOSS_THR = -1 #0.0001\n",
    "OOF_DF_PATH = 'none' #'../../14_Baseline4/exp/result/14_v1_01/oof_df.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "2022-11-17 17:58:04.330585: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 17:58:04.330607: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 48/48 [01:05<00:00,  1.36s/it, loss=1.14]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.26it/s]\n",
      "epoch 1: trn_loss = 1.1367, val_loss = 0.1572, trn_score = 1.9508, val_score = 0.5640\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [01:02<00:00,  1.31s/it, loss=0.159]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.25it/s]\n",
      "epoch 2: trn_loss = 0.1593, val_loss = 0.1233, trn_score = 0.5701, val_score = 0.4986\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [01:03<00:00,  1.33s/it, loss=0.121]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 3: trn_loss = 0.1207, val_loss = 0.1172, trn_score = 0.4931, val_score = 0.4852\n",
      "model (best score) saved\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.113]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.21it/s]\n",
      "epoch 4: trn_loss = 0.1131, val_loss = 0.1134, trn_score = 0.4768, val_score = 0.4772\n",
      "model (best score) saved\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.109]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 5: trn_loss = 0.1087, val_loss = 0.1267, trn_score = 0.4674, val_score = 0.5061\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0976]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 6: trn_loss = 0.0976, val_loss = 0.1135, trn_score = 0.4423, val_score = 0.4782\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.33s/it, loss=0.0912]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 7: trn_loss = 0.0912, val_loss = 0.1108, trn_score = 0.4271, val_score = 0.4720\n",
      "model (best score) saved\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.33s/it, loss=0.0853]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 8: trn_loss = 0.0853, val_loss = 0.1115, trn_score = 0.4131, val_score = 0.4736\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0803]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 9: trn_loss = 0.0803, val_loss = 0.1130, trn_score = 0.4004, val_score = 0.4769\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0783]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 10: trn_loss = 0.0783, val_loss = 0.1158, trn_score = 0.3955, val_score = 0.4828\n",
      " elapsed_time = 12.6 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "LR = 8e-5 #8e-6\n",
    "HEAD_LR = 8e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 64 #8\n",
    "VAL_BS = 64 #8\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0]: #[0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "2022-11-17 21:35:19.896078: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 21:35:19.896100: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 48/48 [01:03<00:00,  1.31s/it, loss=1.04]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.27it/s]\n",
      "epoch 1: trn_loss = 1.0412, val_loss = 0.2132, trn_score = 1.8636, val_score = 0.6651\n",
      "model (best score) saved\n",
      "lr :  [0.0001, 0.0001, 0.001]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=0.135]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.24it/s]\n",
      "epoch 2: trn_loss = 0.1353, val_loss = 0.1217, trn_score = 0.5237, val_score = 0.4948\n",
      "model (best score) saved\n",
      "lr :  [9.709221818197624e-05, 9.709221818197624e-05, 0.0009709221818197624]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.117]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.20it/s]\n",
      "epoch 3: trn_loss = 0.1167, val_loss = 0.1186, trn_score = 0.4846, val_score = 0.4884\n",
      "model (best score) saved\n",
      "lr :  [8.870708053195413e-05, 8.870708053195413e-05, 0.0008870708053195413]\n",
      "100%|███████████████████████████████| 48/48 [01:05<00:00,  1.35s/it, loss=0.117]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.21it/s]\n",
      "epoch 4: trn_loss = 0.1166, val_loss = 0.1334, trn_score = 0.4844, val_score = 0.5193\n",
      "lr :  [7.58198730819481e-05, 7.58198730819481e-05, 0.000758198730819481]\n",
      "100%|███████████████████████████████| 48/48 [01:05<00:00,  1.36s/it, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.21it/s]\n",
      "epoch 5: trn_loss = 0.1028, val_loss = 0.1258, trn_score = 0.4543, val_score = 0.5040\n",
      "lr :  [5.992952333228728e-05, 5.992952333228728e-05, 0.0005992952333228728]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=0.0923]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.21it/s]\n",
      "epoch 6: trn_loss = 0.0923, val_loss = 0.1166, trn_score = 0.4297, val_score = 0.4850\n",
      "model (best score) saved\n",
      "lr :  [4.288425808633575e-05, 4.288425808633575e-05, 0.0004288425808633575]\n",
      "  8%|██▌                            | 4/48 [00:05<01:00,  1.38s/it, loss=0.0812]^C\n"
     ]
    }
   ],
   "source": [
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "LR = 1e-4 #8e-6\n",
    "HEAD_LR = 1e-3 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 64 #8\n",
    "VAL_BS = 64 #8\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0]: #[0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "2022-11-17 21:44:17.660900: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 21:44:17.660920: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  244\n",
      "num_warmup_steps =  24\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 24/24 [01:01<00:00,  2.57s/it, loss=1.58]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.47s/it]\n",
      "epoch 1: trn_loss = 1.5794, val_loss = 0.2843, trn_score = 2.3225, val_score = 0.7770\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.62s/it, loss=0.198]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.49s/it]\n",
      "epoch 2: trn_loss = 0.1977, val_loss = 0.2350, trn_score = 0.6411, val_score = 0.6996\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.189]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.50s/it]\n",
      "epoch 3: trn_loss = 0.1893, val_loss = 0.1333, trn_score = 0.6243, val_score = 0.5176\n",
      "model (best score) saved\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.62s/it, loss=0.139]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.49s/it]\n",
      "epoch 4: trn_loss = 0.1385, val_loss = 0.1202, trn_score = 0.5299, val_score = 0.4915\n",
      "model (best score) saved\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.123]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.49s/it]\n",
      "epoch 5: trn_loss = 0.1225, val_loss = 0.1208, trn_score = 0.4973, val_score = 0.4932\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.113]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.47s/it]\n",
      "epoch 6: trn_loss = 0.1129, val_loss = 0.1115, trn_score = 0.4763, val_score = 0.4733\n",
      "model (best score) saved\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.105]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.47s/it]\n",
      "epoch 7: trn_loss = 0.1046, val_loss = 0.1105, trn_score = 0.4582, val_score = 0.4719\n",
      "model (best score) saved\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.101]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 8: trn_loss = 0.1013, val_loss = 0.1095, trn_score = 0.4507, val_score = 0.4694\n",
      "model (best score) saved\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|██████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.0984]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.49s/it]\n",
      "epoch 9: trn_loss = 0.0984, val_loss = 0.1096, trn_score = 0.4441, val_score = 0.4698\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|██████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.0968]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 10: trn_loss = 0.0968, val_loss = 0.1106, trn_score = 0.4403, val_score = 0.4718\n",
      " elapsed_time = 12.3 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "LR = 8e-5 #8e-6\n",
    "HEAD_LR = 8e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 128 #64 #8\n",
    "VAL_BS = 128 #64 #8\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0]: #[0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "2022-11-17 22:10:48.408943: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 22:10:48.408965: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  244\n",
      "num_warmup_steps =  24\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 24/24 [01:01<00:00,  2.56s/it, loss=1.87]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:09<00:00,  1.42s/it]\n",
      "epoch 1: trn_loss = 1.8682, val_loss = 0.3100, trn_score = 2.5426, val_score = 0.8117\n",
      "model (best score) saved\n",
      "lr :  [5e-05, 5e-05, 0.0005]\n",
      "100%|███████████████████████████████| 24/24 [01:01<00:00,  2.57s/it, loss=0.209]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.46s/it]\n",
      "epoch 2: trn_loss = 0.2092, val_loss = 0.1413, trn_score = 0.6614, val_score = 0.5341\n",
      "model (best score) saved\n",
      "lr :  [4.854610909098812e-05, 4.854610909098812e-05, 0.0004854610909098812]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.138]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n",
      "epoch 3: trn_loss = 0.1381, val_loss = 0.1222, trn_score = 0.5289, val_score = 0.4958\n",
      "model (best score) saved\n",
      "lr :  [4.4353540265977064e-05, 4.4353540265977064e-05, 0.00044353540265977065]\n",
      "100%|████████████████████████████████| 24/24 [01:02<00:00,  2.62s/it, loss=0.12]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n",
      "epoch 4: trn_loss = 0.1201, val_loss = 0.1500, trn_score = 0.4918, val_score = 0.5503\n",
      "lr :  [3.790993654097405e-05, 3.790993654097405e-05, 0.0003790993654097405]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.62s/it, loss=0.116]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 5: trn_loss = 0.1156, val_loss = 0.1139, trn_score = 0.4824, val_score = 0.4790\n",
      "model (best score) saved\n",
      "lr :  [2.996476166614364e-05, 2.996476166614364e-05, 0.0002996476166614364]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.108]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 6: trn_loss = 0.1085, val_loss = 0.1134, trn_score = 0.4669, val_score = 0.4776\n",
      "model (best score) saved\n",
      "lr :  [2.1442129043167874e-05, 2.1442129043167874e-05, 0.00021442129043167875]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.106]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 7: trn_loss = 0.1058, val_loss = 0.1143, trn_score = 0.4608, val_score = 0.4801\n",
      "lr :  [1.3333316919358157e-05, 1.3333316919358157e-05, 0.00013333316919358158]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.103]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 8: trn_loss = 0.1032, val_loss = 0.1111, trn_score = 0.4551, val_score = 0.4728\n",
      "model (best score) saved\n",
      "lr :  [6.5814715530898745e-06, 6.5814715530898745e-06, 6.581471553089874e-05]\n",
      "100%|███████████████████████████████| 24/24 [01:02<00:00,  2.61s/it, loss=0.101]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 9: trn_loss = 0.1015, val_loss = 0.1154, trn_score = 0.4511, val_score = 0.4824\n",
      "lr :  [1.97190867212875e-06, 1.97190867212875e-06, 1.97190867212875e-05]\n",
      "100%|██████████████████████████████| 24/24 [01:02<00:00,  2.62s/it, loss=0.0997]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "epoch 10: trn_loss = 0.0997, val_loss = 0.1139, trn_score = 0.4469, val_score = 0.4790\n",
      " elapsed_time = 12.3 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "LR = 5e-5 #8e-6\n",
    "HEAD_LR = 5e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 128 #64 #8\n",
    "VAL_BS = 128 #64 #8\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0]: #[0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  1\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "2022-11-17 18:10:56.696698: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 18:10:56.696719: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=1.21]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.20it/s]\n",
      "epoch 1: trn_loss = 1.2087, val_loss = 0.1793, trn_score = 2.0459, val_score = 0.6081\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=0.157]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 2: trn_loss = 0.1573, val_loss = 0.1314, trn_score = 0.5658, val_score = 0.5148\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.136]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 3: trn_loss = 0.1358, val_loss = 0.1157, trn_score = 0.5243, val_score = 0.4824\n",
      "model (best score) saved\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.114]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 4: trn_loss = 0.1137, val_loss = 0.1193, trn_score = 0.4781, val_score = 0.4901\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.109]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 5: trn_loss = 0.1090, val_loss = 0.1141, trn_score = 0.4679, val_score = 0.4786\n",
      "model (best score) saved\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0967]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 6: trn_loss = 0.0967, val_loss = 0.1186, trn_score = 0.4402, val_score = 0.4887\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0885]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 7: trn_loss = 0.0885, val_loss = 0.1097, trn_score = 0.4210, val_score = 0.4695\n",
      "model (best score) saved\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0829]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 8: trn_loss = 0.0829, val_loss = 0.1138, trn_score = 0.4071, val_score = 0.4783\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0807]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 9: trn_loss = 0.0807, val_loss = 0.1256, trn_score = 0.4016, val_score = 0.5035\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0774]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 10: trn_loss = 0.0774, val_loss = 0.1170, trn_score = 0.3932, val_score = 0.4853\n",
      " elapsed_time = 12.6 min\n",
      "\n",
      "--------------------------------------------------\n",
      "FOLD =  2\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "2022-11-17 18:23:51.678910: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 18:23:51.678931: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=1.23]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.20it/s]\n",
      "epoch 1: trn_loss = 1.2267, val_loss = 0.1659, trn_score = 2.0394, val_score = 0.5834\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [01:05<00:00,  1.35s/it, loss=0.136]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.21it/s]\n",
      "epoch 2: trn_loss = 0.1358, val_loss = 0.1255, trn_score = 0.5240, val_score = 0.5042\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=0.112]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 3: trn_loss = 0.1122, val_loss = 0.1117, trn_score = 0.4751, val_score = 0.4740\n",
      "model (best score) saved\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 4: trn_loss = 0.1079, val_loss = 0.1175, trn_score = 0.4657, val_score = 0.4866\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0943]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 5: trn_loss = 0.0943, val_loss = 0.1124, trn_score = 0.4346, val_score = 0.4753\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0872]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 6: trn_loss = 0.0872, val_loss = 0.1137, trn_score = 0.4177, val_score = 0.4784\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0763]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 7: trn_loss = 0.0763, val_loss = 0.1200, trn_score = 0.3906, val_score = 0.4921\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0721]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 8: trn_loss = 0.0721, val_loss = 0.1133, trn_score = 0.3794, val_score = 0.4778\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0665]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 9: trn_loss = 0.0665, val_loss = 0.1167, trn_score = 0.3645, val_score = 0.4853\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0645]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 10: trn_loss = 0.0645, val_loss = 0.1157, trn_score = 0.3589, val_score = 0.4833\n",
      " elapsed_time = 12.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "FOLD =  3\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "2022-11-17 18:36:43.564992: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 18:36:43.565012: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=1.36]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.20it/s]\n",
      "epoch 1: trn_loss = 1.3636, val_loss = 0.1655, trn_score = 2.2223, val_score = 0.5791\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=0.159]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 2: trn_loss = 0.1594, val_loss = 0.1576, trn_score = 0.5703, val_score = 0.5650\n",
      "model (best score) saved\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.126]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 3: trn_loss = 0.1263, val_loss = 0.1586, trn_score = 0.5049, val_score = 0.5688\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.122]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 4: trn_loss = 0.1222, val_loss = 0.1479, trn_score = 0.4965, val_score = 0.5479\n",
      "model (best score) saved\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 5: trn_loss = 0.1083, val_loss = 0.1222, trn_score = 0.4664, val_score = 0.4957\n",
      "model (best score) saved\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.104]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 6: trn_loss = 0.1038, val_loss = 0.1299, trn_score = 0.4569, val_score = 0.5118\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0978]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 7: trn_loss = 0.0978, val_loss = 0.1313, trn_score = 0.4428, val_score = 0.5157\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0873]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 8: trn_loss = 0.0873, val_loss = 0.1249, trn_score = 0.4182, val_score = 0.5022\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0822]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 9: trn_loss = 0.0822, val_loss = 0.1263, trn_score = 0.4055, val_score = 0.5052\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0796]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 10: trn_loss = 0.0796, val_loss = 0.1263, trn_score = 0.3991, val_score = 0.5051\n",
      " elapsed_time = 12.6 min\n",
      "\n",
      "--------------------------------------------------\n",
      "FOLD =  4\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "2022-11-17 18:49:37.228758: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 18:49:37.228778: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  488\n",
      "num_warmup_steps =  48\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|████████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=1.19]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.19it/s]\n",
      "epoch 1: trn_loss = 1.1945, val_loss = 0.1450, trn_score = 2.0567, val_score = 0.5412\n",
      "model (best score) saved\n",
      "lr :  [8e-05, 8e-05, 0.0008]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=0.181]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.20it/s]\n",
      "epoch 2: trn_loss = 0.1812, val_loss = 0.1959, trn_score = 0.6102, val_score = 0.6342\n",
      "lr :  [7.7673774545581e-05, 7.7673774545581e-05, 0.0007767377454558099]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.35s/it, loss=0.138]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 3: trn_loss = 0.1377, val_loss = 0.1320, trn_score = 0.5287, val_score = 0.5158\n",
      "model (best score) saved\n",
      "lr :  [7.096566442556331e-05, 7.096566442556331e-05, 0.000709656644255633]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.123]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 4: trn_loss = 0.1232, val_loss = 0.1166, trn_score = 0.4988, val_score = 0.4839\n",
      "model (best score) saved\n",
      "lr :  [6.0655898465558484e-05, 6.0655898465558484e-05, 0.0006065589846555848]\n",
      "100%|████████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.11]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 5: trn_loss = 0.1096, val_loss = 0.1200, trn_score = 0.4694, val_score = 0.4908\n",
      "lr :  [4.794361866582982e-05, 4.794361866582982e-05, 0.0004794361866582982]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.106]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "epoch 6: trn_loss = 0.1056, val_loss = 0.1132, trn_score = 0.4603, val_score = 0.4769\n",
      "model (best score) saved\n",
      "lr :  [3.4307406469068604e-05, 3.4307406469068604e-05, 0.000343074064690686]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0987]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 7: trn_loss = 0.0987, val_loss = 0.1131, trn_score = 0.4448, val_score = 0.4769\n",
      "lr :  [2.1333307070973054e-05, 2.1333307070973054e-05, 0.0002133330707097305]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.092]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 8: trn_loss = 0.0920, val_loss = 0.1136, trn_score = 0.4292, val_score = 0.4777\n",
      "lr :  [1.0530354484943798e-05, 1.0530354484943798e-05, 0.00010530354484943799]\n",
      "100%|██████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.0876]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 9: trn_loss = 0.0876, val_loss = 0.1165, trn_score = 0.4188, val_score = 0.4841\n",
      "lr :  [3.155053875406e-06, 3.155053875406e-06, 3.155053875406e-05]\n",
      "100%|███████████████████████████████| 48/48 [01:04<00:00,  1.34s/it, loss=0.086]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "epoch 10: trn_loss = 0.0860, val_loss = 0.1139, trn_score = 0.4149, val_score = 0.4786\n",
      " elapsed_time = 12.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "MODE = 'train'\n",
    "EPOCHS = 10 #5\n",
    "STOP_EPOCH = 10 #5\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1 #EPOCHS\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'false'\n",
    "FB3_FOLD_PATH = 'none' #'../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     #'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "        FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "        #INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_{TEACHER_VERSION}_pseudo_fold{FOLD}.csv'\n",
    "        #FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "        PRETRAIN_PATH = 'none'\n",
    "        !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --class_name $CLASS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD --low_loss_thr $LOW_LOSS_THR --high_loss_thr $HIGH_LOSS_THR \\\n",
    "        --oof_df_path $OOF_DF_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = '../../00_EDA/00_v1_12/result/' #'../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-17 19:02:30.557698: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 19:02:30.557721: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 13)\n",
      "val_df.shape =  (783, 13)\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "100%|███████████████████████████████████████████| 13/13 [00:09<00:00,  1.34it/s]\n",
      "val_loss=0.1108, val_score=0.4720\n",
      "essay_ids.shape =  (783,)\n",
      "preds.shape =  (783, 6)\n",
      "labels.shape =  (783, 6)\n",
      "losses.shape =  (783, 6)\n",
      "embeds.shape =  (783, 768, 6)\n",
      "--------------------------------------------------\n",
      "FOLD =  1\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-17 19:02:58.908034: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 19:02:58.908054: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "100%|███████████████████████████████████████████| 13/13 [00:09<00:00,  1.34it/s]\n",
      "val_loss=0.1097, val_score=0.4695\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768, 6)\n",
      "--------------------------------------------------\n",
      "FOLD =  2\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-17 19:03:25.456142: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 19:03:25.456161: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "100%|███████████████████████████████████████████| 13/13 [00:09<00:00,  1.35it/s]\n",
      "val_loss=0.1117, val_score=0.4740\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768, 6)\n",
      "--------------------------------------------------\n",
      "FOLD =  3\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-17 19:03:52.008841: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 19:03:52.008862: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "100%|███████████████████████████████████████████| 13/13 [00:09<00:00,  1.34it/s]\n",
      "val_loss=0.1222, val_score=0.4957\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768, 6)\n",
      "--------------------------------------------------\n",
      "FOLD =  4\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-17 19:04:18.865355: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-17 19:04:18.865377: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 13)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 13)\n",
      "val_df.shape =  (782, 13)\n",
      "target_cols =  ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
      "100%|███████████████████████████████████████████| 13/13 [00:09<00:00,  1.35it/s]\n",
      "val_loss=0.1132, val_score=0.4769\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768, 6)\n"
     ]
    }
   ],
   "source": [
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "if True:\n",
    "    CLASS = 'none'\n",
    "    for FOLD in [0,1,2,3,4]:\n",
    "        print(\"-\"*50)\n",
    "        print(\"FOLD = \", FOLD)\n",
    "        print(\"-\"*50)\n",
    "        WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}.pth'\n",
    "        #WEIGHT_PATH = f'./result/{VERSION}/model_{CLASS}_seed{SEED}_fold{FOLD}.pth'\n",
    "        #WEIGHT_PATH = f'result/{VERSION}/model_{CLASS}_seed{SEED}_fold{FOLD}_pseudo.pth'\n",
    "        !python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "        --fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "        --rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN \\\n",
    "        --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS \\\n",
    "        --class_name $CLASS --input_path $INPUT_PATH --use_stats $USE_STATS \\\n",
    "        --use_separate_head $USE_SEPARATE_HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "preds = []\n",
    "# for CLASS in [\n",
    "#     'cohesion',\n",
    "#     'syntax','vocabulary','phraseology','grammar','conventions'\n",
    "# ]:\n",
    "#     print(\"*\"*50)\n",
    "#     print(CLASS)\n",
    "#     print(\"*\"*50)\n",
    "#     preds_class = []\n",
    "if True:\n",
    "    for fold in [0,1,2,3,4]:\n",
    "        tmp_df = pd.read_csv(f'./result/{VERSION}/pred_fold{fold}.csv')\n",
    "        #tmp_df = pd.read_csv(f'./result/{VERSION}/pred_{CLASS}_fold{fold}.csv')\n",
    "        #embeds = np.load(f'./result/{VERSION}/embeds_{CLASS}_fold{fold}.npz')['arr_0']\n",
    "        #tmp_df[f'embed_{CLASS}'] = embeds.tolist()\n",
    "        #preds_class.append(tmp_df)\n",
    "        preds.append(tmp_df)\n",
    "#     pred_df = pd.concat(preds_class, axis=0).reset_index(drop=True)\n",
    "#     if len(preds)==0:\n",
    "#         preds.append(pred_df)\n",
    "#     else:\n",
    "#         del pred_df[\"text_id\"]\n",
    "#         preds.append(pred_df)\n",
    "    \n",
    "#all_pred_df = pd.concat(preds, axis=1)\n",
    "all_pred_df = pd.concat(preds, axis=0).reset_index(drop=True)\n",
    "\n",
    "train_df = pd.read_csv('../../input/feedback-prize-english-language-learning/train.csv')\n",
    "oof_df = train_df[['text_id']].merge(all_pred_df, on='text_id', how='left')\n",
    "oof_df.to_csv(f'./result/{VERSION}/oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3911, 13),\n",
       " text_id             0\n",
       " cohesion            0\n",
       " syntax              0\n",
       " vocabulary          0\n",
       " phraseology         0\n",
       " grammar             0\n",
       " conventions         0\n",
       " loss_cohesion       0\n",
       " loss_syntax         0\n",
       " loss_vocabulary     0\n",
       " loss_phraseology    0\n",
       " loss_grammar        0\n",
       " loss_conventions    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df.shape, oof_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.103984</td>\n",
       "      <td>2.981356</td>\n",
       "      <td>3.229528</td>\n",
       "      <td>3.120537</td>\n",
       "      <td>3.019616</td>\n",
       "      <td>3.119927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.444373</td>\n",
       "      <td>0.454010</td>\n",
       "      <td>0.399267</td>\n",
       "      <td>0.467868</td>\n",
       "      <td>0.506382</td>\n",
       "      <td>0.493622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.312808</td>\n",
       "      <td>1.315190</td>\n",
       "      <td>1.883673</td>\n",
       "      <td>1.521473</td>\n",
       "      <td>1.426871</td>\n",
       "      <td>1.097013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.798807</td>\n",
       "      <td>2.667198</td>\n",
       "      <td>2.952932</td>\n",
       "      <td>2.795291</td>\n",
       "      <td>2.665023</td>\n",
       "      <td>2.778230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.096207</td>\n",
       "      <td>2.971432</td>\n",
       "      <td>3.217556</td>\n",
       "      <td>3.117929</td>\n",
       "      <td>3.015521</td>\n",
       "      <td>3.122659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.412023</td>\n",
       "      <td>3.285943</td>\n",
       "      <td>3.487809</td>\n",
       "      <td>3.434765</td>\n",
       "      <td>3.355352</td>\n",
       "      <td>3.465267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.542235</td>\n",
       "      <td>4.477060</td>\n",
       "      <td>4.679187</td>\n",
       "      <td>4.627151</td>\n",
       "      <td>4.633020</td>\n",
       "      <td>4.602295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cohesion       syntax   vocabulary  phraseology      grammar  \\\n",
       "count  3911.000000  3911.000000  3911.000000  3911.000000  3911.000000   \n",
       "mean      3.103984     2.981356     3.229528     3.120537     3.019616   \n",
       "std       0.444373     0.454010     0.399267     0.467868     0.506382   \n",
       "min       1.312808     1.315190     1.883673     1.521473     1.426871   \n",
       "25%       2.798807     2.667198     2.952932     2.795291     2.665023   \n",
       "50%       3.096207     2.971432     3.217556     3.117929     3.015521   \n",
       "75%       3.412023     3.285943     3.487809     3.434765     3.355352   \n",
       "max       4.542235     4.477060     4.679187     4.627151     4.633020   \n",
       "\n",
       "       conventions  \n",
       "count  3911.000000  \n",
       "mean      3.119927  \n",
       "std       0.493622  \n",
       "min       1.097013  \n",
       "25%       2.778230  \n",
       "50%       3.122659  \n",
       "75%       3.465267  \n",
       "max       4.602295  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.127077</td>\n",
       "      <td>3.028254</td>\n",
       "      <td>3.235745</td>\n",
       "      <td>3.116850</td>\n",
       "      <td>3.032856</td>\n",
       "      <td>3.081053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.662542</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>0.583148</td>\n",
       "      <td>0.655997</td>\n",
       "      <td>0.699841</td>\n",
       "      <td>0.671450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cohesion       syntax   vocabulary  phraseology      grammar  \\\n",
       "count  3911.000000  3911.000000  3911.000000  3911.000000  3911.000000   \n",
       "mean      3.127077     3.028254     3.235745     3.116850     3.032856   \n",
       "std       0.662542     0.644399     0.583148     0.655997     0.699841   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       2.500000     2.500000     3.000000     2.500000     2.500000   \n",
       "50%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.500000     3.500000     3.500000     3.500000     3.500000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "       conventions  \n",
       "count  3911.000000  \n",
       "mean      3.081053  \n",
       "std       0.671450  \n",
       "min       1.000000  \n",
       "25%       2.500000  \n",
       "50%       3.000000  \n",
       "75%       3.500000  \n",
       "max       5.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis - Check Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695459</td>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.666151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>0.695459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680562</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.700025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.680562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>0.654852</td>\n",
       "      <td>0.664292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.666842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.654852</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.700025</td>\n",
       "      <td>0.664292</td>\n",
       "      <td>0.666842</td>\n",
       "      <td>0.673301</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "cohesion     1.000000  0.695459    0.666151     0.690058  0.638689   \n",
       "syntax       0.695459  1.000000    0.680562     0.725467  0.709525   \n",
       "vocabulary   0.666151  0.680562    1.000000     0.735261  0.654852   \n",
       "phraseology  0.690058  0.725467    0.735261     1.000000  0.719746   \n",
       "grammar      0.638689  0.709525    0.654852     0.719746  1.000000   \n",
       "conventions  0.666151  0.700025    0.664292     0.666842  0.673301   \n",
       "\n",
       "             conventions  \n",
       "cohesion        0.666151  \n",
       "syntax          0.700025  \n",
       "vocabulary      0.664292  \n",
       "phraseology     0.666842  \n",
       "grammar         0.673301  \n",
       "conventions     1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955518</td>\n",
       "      <td>0.966482</td>\n",
       "      <td>0.959743</td>\n",
       "      <td>0.895714</td>\n",
       "      <td>0.949279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>0.955518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958382</td>\n",
       "      <td>0.946452</td>\n",
       "      <td>0.938954</td>\n",
       "      <td>0.954726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>0.966482</td>\n",
       "      <td>0.958382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974098</td>\n",
       "      <td>0.913602</td>\n",
       "      <td>0.928874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>0.959743</td>\n",
       "      <td>0.946452</td>\n",
       "      <td>0.974098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944753</td>\n",
       "      <td>0.924003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>0.895714</td>\n",
       "      <td>0.938954</td>\n",
       "      <td>0.913602</td>\n",
       "      <td>0.944753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>0.949279</td>\n",
       "      <td>0.954726</td>\n",
       "      <td>0.928874</td>\n",
       "      <td>0.924003</td>\n",
       "      <td>0.934811</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "cohesion     1.000000  0.955518    0.966482     0.959743  0.895714   \n",
       "syntax       0.955518  1.000000    0.958382     0.946452  0.938954   \n",
       "vocabulary   0.966482  0.958382    1.000000     0.974098  0.913602   \n",
       "phraseology  0.959743  0.946452    0.974098     1.000000  0.944753   \n",
       "grammar      0.895714  0.938954    0.913602     0.944753  1.000000   \n",
       "conventions  0.949279  0.954726    0.928874     0.924003  0.934811   \n",
       "\n",
       "             conventions  \n",
       "cohesion        0.949279  \n",
       "syntax          0.954726  \n",
       "vocabulary      0.928874  \n",
       "phraseology     0.924003  \n",
       "grammar         0.934811  \n",
       "conventions     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
