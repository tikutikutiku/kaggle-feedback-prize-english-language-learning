{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '18_v1_05'\n",
    "MODEL = 'microsoft/deberta-v3-small'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'bert-large-cased'\n",
    "#'bert-large-cased-whole-word-masking'\n",
    "#'albert-large-v2'\n",
    "#'facebook/bart-large'\n",
    "#'xlm-roberta-large'\n",
    "#'deepset/roberta-large-squad2'\n",
    "#'google/electra-large-discriminator'\n",
    "#'sentence-transformeres/paraphrase-mpnet-base-v2'\n",
    "#'funnel-transformer/large-base'\n",
    "#'facebook/bart-base'\n",
    "#'distilroberta-base'\n",
    "#'deepset/roberta-base-squad2'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'roberta-large'\n",
    "#'roberta-base'\n",
    "#'microsoft/deberta-v3-large'\n",
    "#'microsoft/deberta-base'\n",
    "LR = 1e-4 #2e-5 #8e-6\n",
    "HEAD_LR = 1e-3 #2e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 8\n",
    "VAL_BS = 8\n",
    "ACCUM_STEP = 1\n",
    "HIDDEN_DROP_PROB = 0\n",
    "P_DROP = 0\n",
    "RNN = 'none'\n",
    "WARMUP_RATIO = 0.1\n",
    "HEAD = 'simple'\n",
    "AUG = 'false'\n",
    "MIXUP_ALPHA = 0\n",
    "P_AUG = 0\n",
    "AUG_STOP_EPOCH = 0\n",
    "MSD = 'false'\n",
    "POOLING = 'mean' #'weighted_layer'\n",
    "NUM_POOLING_LAYERS = 4 #1\n",
    "MULTI_LAYERS = 1\n",
    "EVAL_STEP_START_EPOCH = -1\n",
    "EVAL_STEP = -1\n",
    "NUM_LABELS = 6\n",
    "NUM_LABELS_2 = -1\n",
    "FP16 = 'true'\n",
    "WD = 0.01\n",
    "FREEZE = 'false'\n",
    "MULTI_TASK = 'false' \n",
    "W_MT = 0 \n",
    "AWP = 'false'\n",
    "AWP_LR = 0\n",
    "AWP_EPS = 0\n",
    "AWP_START_EPOCH = -1\n",
    "#PRETRAINED_DETECTOR_PATH = f'../../input/tascj/result/deberta_base_fold0.pth'\n",
    "PRETRAINED_DETECTOR_PATH = 'none' #f'../../05_Detection/exp/result/05_v2_09/model_seed100_fold0_swa.pth'\n",
    "MASK_PROB = 0 #0.8\n",
    "MASK_RATIO = 0 #0.3\n",
    "SCHEDULER = 'cosine_hard'\n",
    "CP = 'true' #'false'\n",
    "WINDOW_SIZE = -1 #512\n",
    "INNER_LEN = -1 #384\n",
    "EDGE_LEN = -1 #64\n",
    "MAX_LEN = 512\n",
    "\n",
    "GRAD_CLIP = 1\n",
    "\n",
    "LOSS = 'smoothl1'#'mse'\n",
    "\n",
    "CROP_PROB = 0 #1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Pseudo-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  pseudo\n",
      "train_df.shape =  (15142, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (12113, 8)\n",
      "val_df.shape =  (3029, 8)\n",
      "adding fb3 data...\n",
      "trn_df.columns =  Index(['essay_id', 'cohesion', 'syntax', 'vocabulary', 'phraseology',\n",
      "       'grammar', 'conventions', 'full_text'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.columns =  Index(['essay_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
      "       'phraseology', 'grammar', 'conventions'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.shape =  (3128, 8)\n",
      "fb3_trn_df[trn_df.columns].shape =  (3128, 8)\n",
      "adding fb3 data, done\n",
      "trn_df.shape =  (15241, 8)\n",
      "2022-11-03 20:43:59.986042: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 20:43:59.986068: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1905\n",
      "num_warmup_steps =  190\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|██████████████████████████| 1905/1905 [06:30<00:00,  4.88it/s, loss=0.0777]\n",
      "100%|█████████████████████████████████████████| 379/379 [00:59<00:00,  6.40it/s]\n",
      "epoch 1: trn_loss = 0.0777, val_loss = 0.0029, trn_score = 0.4861, val_score = 0.0754\n",
      "model (best score) saved\n",
      "\n",
      "--------------------------------------------------\n",
      "FOLD =  1\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  pseudo\n",
      "train_df.shape =  (15142, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (12113, 8)\n",
      "val_df.shape =  (3029, 8)\n",
      "adding fb3 data...\n",
      "trn_df.columns =  Index(['essay_id', 'cohesion', 'syntax', 'vocabulary', 'phraseology',\n",
      "       'grammar', 'conventions', 'full_text'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.columns =  Index(['essay_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
      "       'phraseology', 'grammar', 'conventions'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.shape =  (3129, 8)\n",
      "fb3_trn_df[trn_df.columns].shape =  (3129, 8)\n",
      "adding fb3 data, done\n",
      "trn_df.shape =  (15242, 8)\n",
      "2022-11-03 20:51:47.864645: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 20:51:47.864669: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1905\n",
      "num_warmup_steps =  190\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|██████████████████████████| 1905/1905 [06:33<00:00,  4.84it/s, loss=0.0868]\n",
      "100%|█████████████████████████████████████████| 379/379 [00:58<00:00,  6.46it/s]\n",
      "epoch 1: trn_loss = 0.0868, val_loss = 0.0030, trn_score = 0.5362, val_score = 0.0772\n",
      "model (best score) saved\n",
      "\n",
      "--------------------------------------------------\n",
      "FOLD =  2\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  pseudo\n",
      "train_df.shape =  (15142, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (12114, 8)\n",
      "val_df.shape =  (3028, 8)\n",
      "adding fb3 data...\n",
      "trn_df.columns =  Index(['essay_id', 'cohesion', 'syntax', 'vocabulary', 'phraseology',\n",
      "       'grammar', 'conventions', 'full_text'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.columns =  Index(['essay_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
      "       'phraseology', 'grammar', 'conventions'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.shape =  (3129, 8)\n",
      "fb3_trn_df[trn_df.columns].shape =  (3129, 8)\n",
      "adding fb3 data, done\n",
      "trn_df.shape =  (15243, 8)\n",
      "2022-11-03 20:59:38.226180: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 20:59:38.226202: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1905\n",
      "num_warmup_steps =  190\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|██████████████████████████| 1905/1905 [06:32<00:00,  4.85it/s, loss=0.0789]\n",
      "100%|█████████████████████████████████████████| 379/379 [00:59<00:00,  6.42it/s]\n",
      "epoch 1: trn_loss = 0.0789, val_loss = 0.0032, trn_score = 0.4930, val_score = 0.0801\n",
      "model (best score) saved\n",
      "\n",
      "--------------------------------------------------\n",
      "FOLD =  3\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  pseudo\n",
      "train_df.shape =  (15142, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (12114, 8)\n",
      "val_df.shape =  (3028, 8)\n",
      "adding fb3 data...\n",
      "trn_df.columns =  Index(['essay_id', 'cohesion', 'syntax', 'vocabulary', 'phraseology',\n",
      "       'grammar', 'conventions', 'full_text'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.columns =  Index(['essay_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
      "       'phraseology', 'grammar', 'conventions'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.shape =  (3129, 8)\n",
      "fb3_trn_df[trn_df.columns].shape =  (3129, 8)\n",
      "adding fb3 data, done\n",
      "trn_df.shape =  (15243, 8)\n",
      "2022-11-03 21:07:27.409375: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 21:07:27.409399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1905\n",
      "num_warmup_steps =  190\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|██████████████████████████| 1905/1905 [06:35<00:00,  4.82it/s, loss=0.0725]\n",
      "100%|█████████████████████████████████████████| 379/379 [00:59<00:00,  6.41it/s]\n",
      "epoch 1: trn_loss = 0.0725, val_loss = 0.0029, trn_score = 0.4633, val_score = 0.0762\n",
      "model (best score) saved\n",
      "\n",
      "--------------------------------------------------\n",
      "FOLD =  4\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "args.mode =  pseudo\n",
      "train_df.shape =  (15142, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (12114, 8)\n",
      "val_df.shape =  (3028, 8)\n",
      "adding fb3 data...\n",
      "trn_df.columns =  Index(['essay_id', 'cohesion', 'syntax', 'vocabulary', 'phraseology',\n",
      "       'grammar', 'conventions', 'full_text'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.columns =  Index(['essay_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
      "       'phraseology', 'grammar', 'conventions'],\n",
      "      dtype='object')\n",
      "fb3_trn_df.shape =  (3129, 8)\n",
      "fb3_trn_df[trn_df.columns].shape =  (3129, 8)\n",
      "adding fb3 data, done\n",
      "trn_df.shape =  (15243, 8)\n",
      "2022-11-03 21:15:19.445322: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 21:15:19.445346: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1905\n",
      "num_warmup_steps =  190\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|██████████████████████████| 1905/1905 [06:33<00:00,  4.84it/s, loss=0.0822]\n",
      "100%|█████████████████████████████████████████| 379/379 [00:58<00:00,  6.46it/s]\n",
      "epoch 1: trn_loss = 0.0822, val_loss = 0.0033, trn_score = 0.5078, val_score = 0.0811\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'pseudo'\n",
    "EPOCHS = 1 #8\n",
    "STOP_EPOCH = 1 #3\n",
    "RESTART = 1\n",
    "NUM_CYCLES = 1\n",
    "EVAL_STEP = -1\n",
    "ADD_FB3 = 'true'\n",
    "FB3_FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "\n",
    "for FOLD in [0,1,2,3,4]:\n",
    "    print(\"-\"*50)\n",
    "    print(\"FOLD = \", FOLD)\n",
    "    print(\"-\"*50)\n",
    "    #INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "    #FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "    INPUT_PATH = f'../../99_Ensemble/99_v1_03/result/99_v1_03_03_pseudo_fold{FOLD}.csv'\n",
    "    FOLD_PATH = '../../00_EDA/00_v1_08/result/' # for pseudo-label\n",
    "    PRETRAIN_PATH = 'none'\n",
    "    !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "        --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "        --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "        --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "        --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "        --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "        --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "        --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "        --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "        --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "        --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "        --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "        --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "        --gradient_clip_val $GRAD_CLIP \\\n",
    "        --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "        --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS \\\n",
    "        --add_fb3 $ADD_FB3 --fb3_fold_path $FB3_FOLD_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-03 21:23:08.668345: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 21:23:08.668366: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:09<00:00, 10.48it/s]\n",
      "val_loss=0.1021, val_score=0.4520\n",
      "essay_ids.shape =  (783,)\n",
      "preds.shape =  (783, 6)\n",
      "labels.shape =  (783, 6)\n",
      "losses.shape =  (783, 6)\n",
      "embeds.shape =  (783, 768)\n",
      "--------------------------------------------------\n",
      "FOLD =  1\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-03 21:23:35.301581: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 21:23:35.301605: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:09<00:00, 10.62it/s]\n",
      "val_loss=0.1001, val_score=0.4484\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n",
      "--------------------------------------------------\n",
      "FOLD =  2\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-03 21:24:01.463217: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 21:24:01.463238: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:09<00:00, 10.60it/s]\n",
      "val_loss=0.0981, val_score=0.4434\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n",
      "--------------------------------------------------\n",
      "FOLD =  3\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-03 21:24:27.496228: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 21:24:27.496251: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:09<00:00, 10.54it/s]\n",
      "val_loss=0.1032, val_score=0.4550\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n",
      "--------------------------------------------------\n",
      "FOLD =  4\n",
      "--------------------------------------------------\n",
      "torch 1.10.1\n",
      "2022-11-03 21:24:53.688513: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-11-03 21:24:53.688537: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:09<00:00, 10.52it/s]\n",
      "val_loss=0.1016, val_score=0.4514\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n"
     ]
    }
   ],
   "source": [
    "for FOLD in [0,1,2,3,4]:\n",
    "    print(\"-\"*50)\n",
    "    print(\"FOLD = \", FOLD)\n",
    "    print(\"-\"*50)\n",
    "    #WEIGHT_PATH = f'./result/{VERSION}/model_{CLASS}_seed{SEED}_fold{FOLD}.pth'\n",
    "    #WEIGHT_PATH = f'result/{VERSION}/model_{CLASS}_seed{SEED}_fold{FOLD}_pseudo.pth'\n",
    "    WEIGHT_PATH = f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_pseudo.pth'\n",
    "    !python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "        --fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "        --rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "        --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN \\\n",
    "        --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FOLD =  0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "FOLD =  1\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "FOLD =  2\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "FOLD =  3\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "FOLD =  4\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "preds = []\n",
    "for fold in [0,1,2,3,4]:\n",
    "    print(\"-\"*50)\n",
    "    print(\"FOLD = \", fold)\n",
    "    print(\"-\"*50)\n",
    "    pred_df = pd.read_csv(f'./result/{VERSION}/pred_fold{fold}.csv')\n",
    "    preds.append(pred_df)\n",
    "    \n",
    "all_pred_df = pd.concat(preds, axis=0).reset_index(drop=True)\n",
    "\n",
    "train_df = pd.read_csv('../../input/feedback-prize-english-language-learning/train.csv')\n",
    "oof_df = train_df[['text_id']].merge(all_pred_df, on='text_id', how='left')\n",
    "oof_df.to_csv(f'./result/{VERSION}/oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3911, 13),\n",
       " text_id             0\n",
       " cohesion            0\n",
       " syntax              0\n",
       " vocabulary          0\n",
       " phraseology         0\n",
       " grammar             0\n",
       " conventions         0\n",
       " loss_cohesion       0\n",
       " loss_syntax         0\n",
       " loss_vocabulary     0\n",
       " loss_phraseology    0\n",
       " loss_grammar        0\n",
       " loss_conventions    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df.shape, oof_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.165165</td>\n",
       "      <td>3.065635</td>\n",
       "      <td>3.264277</td>\n",
       "      <td>3.154621</td>\n",
       "      <td>3.062887</td>\n",
       "      <td>3.115073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.454028</td>\n",
       "      <td>0.478094</td>\n",
       "      <td>0.415193</td>\n",
       "      <td>0.483526</td>\n",
       "      <td>0.539834</td>\n",
       "      <td>0.507745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.454799</td>\n",
       "      <td>1.615127</td>\n",
       "      <td>2.025085</td>\n",
       "      <td>1.675162</td>\n",
       "      <td>1.716072</td>\n",
       "      <td>1.321956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.851507</td>\n",
       "      <td>2.725368</td>\n",
       "      <td>2.972057</td>\n",
       "      <td>2.811307</td>\n",
       "      <td>2.654935</td>\n",
       "      <td>2.762121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.171933</td>\n",
       "      <td>3.061910</td>\n",
       "      <td>3.249288</td>\n",
       "      <td>3.151629</td>\n",
       "      <td>3.060959</td>\n",
       "      <td>3.117373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.486108</td>\n",
       "      <td>3.398064</td>\n",
       "      <td>3.541250</td>\n",
       "      <td>3.491093</td>\n",
       "      <td>3.454677</td>\n",
       "      <td>3.475404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.768022</td>\n",
       "      <td>4.653585</td>\n",
       "      <td>5.083294</td>\n",
       "      <td>4.784226</td>\n",
       "      <td>4.684932</td>\n",
       "      <td>4.690524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cohesion       syntax   vocabulary  phraseology      grammar  \\\n",
       "count  3911.000000  3911.000000  3911.000000  3911.000000  3911.000000   \n",
       "mean      3.165165     3.065635     3.264277     3.154621     3.062887   \n",
       "std       0.454028     0.478094     0.415193     0.483526     0.539834   \n",
       "min       1.454799     1.615127     2.025085     1.675162     1.716072   \n",
       "25%       2.851507     2.725368     2.972057     2.811307     2.654935   \n",
       "50%       3.171933     3.061910     3.249288     3.151629     3.060959   \n",
       "75%       3.486108     3.398064     3.541250     3.491093     3.454677   \n",
       "max       4.768022     4.653585     5.083294     4.784226     4.684932   \n",
       "\n",
       "       conventions  \n",
       "count  3911.000000  \n",
       "mean      3.115073  \n",
       "std       0.507745  \n",
       "min       1.321956  \n",
       "25%       2.762121  \n",
       "50%       3.117373  \n",
       "75%       3.475404  \n",
       "max       4.690524  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.127077</td>\n",
       "      <td>3.028254</td>\n",
       "      <td>3.235745</td>\n",
       "      <td>3.116850</td>\n",
       "      <td>3.032856</td>\n",
       "      <td>3.081053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.662542</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>0.583148</td>\n",
       "      <td>0.655997</td>\n",
       "      <td>0.699841</td>\n",
       "      <td>0.671450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cohesion       syntax   vocabulary  phraseology      grammar  \\\n",
       "count  3911.000000  3911.000000  3911.000000  3911.000000  3911.000000   \n",
       "mean      3.127077     3.028254     3.235745     3.116850     3.032856   \n",
       "std       0.662542     0.644399     0.583148     0.655997     0.699841   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       2.500000     2.500000     3.000000     2.500000     2.500000   \n",
       "50%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.500000     3.500000     3.500000     3.500000     3.500000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "       conventions  \n",
       "count  3911.000000  \n",
       "mean      3.081053  \n",
       "std       0.671450  \n",
       "min       1.000000  \n",
       "25%       2.500000  \n",
       "50%       3.000000  \n",
       "75%       3.500000  \n",
       "max       5.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis - Check Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695459</td>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.666151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>0.695459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680562</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.700025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.680562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>0.654852</td>\n",
       "      <td>0.664292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.666842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.654852</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.700025</td>\n",
       "      <td>0.664292</td>\n",
       "      <td>0.666842</td>\n",
       "      <td>0.673301</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "cohesion     1.000000  0.695459    0.666151     0.690058  0.638689   \n",
       "syntax       0.695459  1.000000    0.680562     0.725467  0.709525   \n",
       "vocabulary   0.666151  0.680562    1.000000     0.735261  0.654852   \n",
       "phraseology  0.690058  0.725467    0.735261     1.000000  0.719746   \n",
       "grammar      0.638689  0.709525    0.654852     0.719746  1.000000   \n",
       "conventions  0.666151  0.700025    0.664292     0.666842  0.673301   \n",
       "\n",
       "             conventions  \n",
       "cohesion        0.666151  \n",
       "syntax          0.700025  \n",
       "vocabulary      0.664292  \n",
       "phraseology     0.666842  \n",
       "grammar         0.673301  \n",
       "conventions     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963652</td>\n",
       "      <td>0.932980</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.840773</td>\n",
       "      <td>0.900683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>0.963652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953904</td>\n",
       "      <td>0.971879</td>\n",
       "      <td>0.930448</td>\n",
       "      <td>0.935527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>0.932980</td>\n",
       "      <td>0.953904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971501</td>\n",
       "      <td>0.891098</td>\n",
       "      <td>0.906467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.971879</td>\n",
       "      <td>0.971501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953992</td>\n",
       "      <td>0.895326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>0.840773</td>\n",
       "      <td>0.930448</td>\n",
       "      <td>0.891098</td>\n",
       "      <td>0.953992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.935527</td>\n",
       "      <td>0.906467</td>\n",
       "      <td>0.895326</td>\n",
       "      <td>0.860639</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "cohesion     1.000000  0.963652    0.932980     0.927901  0.840773   \n",
       "syntax       0.963652  1.000000    0.953904     0.971879  0.930448   \n",
       "vocabulary   0.932980  0.953904    1.000000     0.971501  0.891098   \n",
       "phraseology  0.927901  0.971879    0.971501     1.000000  0.953992   \n",
       "grammar      0.840773  0.930448    0.891098     0.953992  1.000000   \n",
       "conventions  0.900683  0.935527    0.906467     0.895326  0.860639   \n",
       "\n",
       "             conventions  \n",
       "cohesion        0.900683  \n",
       "syntax          0.935527  \n",
       "vocabulary      0.906467  \n",
       "phraseology     0.895326  \n",
       "grammar         0.860639  \n",
       "conventions     1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
