{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '15_v1_02'\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "#'bert-large-cased'\n",
    "#'bert-large-cased-whole-word-masking'\n",
    "#'albert-large-v2'\n",
    "#'facebook/bart-large'\n",
    "#'xlm-roberta-large'\n",
    "#'deepset/roberta-large-squad2'\n",
    "#'google/electra-large-discriminator'\n",
    "#'sentence-transformeres/paraphrase-mpnet-base-v2'\n",
    "#'funnel-transformer/large-base'\n",
    "#'facebook/bart-base'\n",
    "#'distilroberta-base'\n",
    "#'deepset/roberta-base-squad2'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'roberta-large'\n",
    "#'roberta-base'\n",
    "#'microsoft/deberta-v3-large'\n",
    "#'microsoft/deberta-base'\n",
    "LR = 2e-5 #8e-6\n",
    "HEAD_LR = 2e-4 #2e-5 #8e-6 \n",
    "SEED = 100\n",
    "TRN_BS = 8\n",
    "VAL_BS = 8\n",
    "ACCUM_STEP = 1\n",
    "HIDDEN_DROP_PROB = 0\n",
    "P_DROP = 0\n",
    "RNN = 'none'\n",
    "WARMUP_RATIO = 0.1\n",
    "HEAD = 'mlp' #'simple'\n",
    "AUG = 'false'\n",
    "MIXUP_ALPHA = 0\n",
    "P_AUG = 0\n",
    "AUG_STOP_EPOCH = 0\n",
    "MSD = 'false'\n",
    "POOLING = 'mean' #'weighted_layer'\n",
    "NUM_POOLING_LAYERS = 4 #1\n",
    "MULTI_LAYERS = 1\n",
    "EVAL_STEP_START_EPOCH = -1\n",
    "EVAL_STEP = -1\n",
    "NUM_LABELS = 6\n",
    "NUM_LABELS_2 = -1\n",
    "FP16 = 'true'\n",
    "WD = 0.01\n",
    "FREEZE = 'false'\n",
    "MULTI_TASK = 'false' \n",
    "W_MT = 0 \n",
    "AWP = 'false'\n",
    "AWP_LR = 0\n",
    "AWP_EPS = 0\n",
    "AWP_START_EPOCH = -1\n",
    "#PRETRAINED_DETECTOR_PATH = f'../../input/tascj/result/deberta_base_fold0.pth'\n",
    "PRETRAINED_DETECTOR_PATH = 'none' #f'../../05_Detection/exp/result/05_v2_09/model_seed100_fold0_swa.pth'\n",
    "MASK_PROB = 0 #0.8\n",
    "MASK_RATIO = 0 #0.3\n",
    "SCHEDULER = 'cosine_hard'\n",
    "CP = 'true' #'false'\n",
    "WINDOW_SIZE = -1 #512\n",
    "INNER_LEN = -1 #384\n",
    "EDGE_LEN = -1 #64\n",
    "MAX_LEN = -1 #512\n",
    "\n",
    "GRAD_CLIP = 1\n",
    "\n",
    "LOSS = 'smoothl1'#'mse'\n",
    "\n",
    "CROP_PROB = 0 #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "2022-10-16 17:27:11.576313: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 17:27:11.576335: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [06:11<00:00,  1.05it/s, loss=0.306]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:46<00:00,  2.12it/s]\n",
      "epoch 1: trn_loss = 0.3060, val_loss = 0.1100, trn_score = 0.9382, val_score = 0.4699\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:10<00:00,  1.06it/s, loss=0.109]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:46<00:00,  2.12it/s]\n",
      "epoch 2: trn_loss = 0.1086, val_loss = 0.1055, trn_score = 0.4674, val_score = 0.4597\n",
      "model (best score) saved\n",
      "lr :  [4.974257968932691e-06, 4.974257968932691e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:06<00:00,  1.07it/s, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:46<00:00,  2.12it/s]\n",
      "epoch 3: trn_loss = 0.1033, val_loss = 0.1049, trn_score = 0.4556, val_score = 0.4583\n",
      "model (best score) saved\n",
      "lr :  [2.3268220525837457e-06, 2.3268220525837457e-06, 2.3268220525837457e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:03<00:00,  1.08it/s, loss=0.101]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:46<00:00,  2.11it/s]\n",
      "epoch 4: trn_loss = 0.1006, val_loss = 0.1028, trn_score = 0.4495, val_score = 0.4535\n",
      "model (best score) saved\n",
      "lr :  [5.996867213330993e-07, 5.996867213330993e-07, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [06:11<00:00,  1.05it/s, loss=0.0973]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:46<00:00,  2.11it/s]\n",
      "epoch 5: trn_loss = 0.0973, val_loss = 0.1017, trn_score = 0.4418, val_score = 0.4510\n",
      "model (best score) saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for FOLD in [0]: #[0,1,2,3,4]:\n",
    "    INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "    FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "    MODE = 'train'\n",
    "    EPOCHS = 5\n",
    "    STOP_EPOCH = 5\n",
    "    RESTART = 1\n",
    "    NUM_CYCLES = EPOCHS\n",
    "    PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "    !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "    --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "    --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "    --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "    --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "    --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "    --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "    --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "    --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "    --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "    --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "    --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "    --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "    --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "    --gradient_clip_val $GRAD_CLIP \\\n",
    "    --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "    --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-10-16 18:02:25.259497: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 18:02:25.259518: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [06:23<00:00,  1.02it/s, loss=0.315]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:41<00:00,  2.36it/s]\n",
      "epoch 1: trn_loss = 0.3154, val_loss = 0.1074, trn_score = 0.9610, val_score = 0.4648\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:11<00:00,  1.05it/s, loss=0.109]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:42<00:00,  2.30it/s]\n",
      "epoch 2: trn_loss = 0.1090, val_loss = 0.1015, trn_score = 0.4680, val_score = 0.4516\n",
      "model (best score) saved\n",
      "lr :  [4.974257968932691e-06, 4.974257968932691e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:17<00:00,  1.04it/s, loss=0.105]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:42<00:00,  2.31it/s]\n",
      "epoch 3: trn_loss = 0.1048, val_loss = 0.1021, trn_score = 0.4587, val_score = 0.4531\n",
      "lr :  [2.3268220525837457e-06, 2.3268220525837457e-06, 2.3268220525837457e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:15<00:00,  1.04it/s, loss=0.105]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:42<00:00,  2.31it/s]\n",
      "epoch 4: trn_loss = 0.1047, val_loss = 0.1004, trn_score = 0.4585, val_score = 0.4489\n",
      "model (best score) saved\n",
      "lr :  [5.996867213330993e-07, 5.996867213330993e-07, 5.996867213330992e-06]\n",
      "100%|█████████████████████████████| 391/391 [06:16<00:00,  1.04it/s, loss=0.098]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:42<00:00,  2.31it/s]\n",
      "epoch 5: trn_loss = 0.0980, val_loss = 0.0995, trn_score = 0.4434, val_score = 0.4470\n",
      "model (best score) saved\n",
      "\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-10-16 18:37:42.718402: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 18:37:42.718424: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|██████████████████████████████| 391/391 [06:09<00:00,  1.06it/s, loss=0.31]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:44<00:00,  2.18it/s]\n",
      "epoch 1: trn_loss = 0.3101, val_loss = 0.1153, trn_score = 0.9394, val_score = 0.4815\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:07<00:00,  1.06it/s, loss=0.107]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:44<00:00,  2.20it/s]\n",
      "epoch 2: trn_loss = 0.1071, val_loss = 0.1003, trn_score = 0.4639, val_score = 0.4489\n",
      "model (best score) saved\n",
      "lr :  [4.974257968932691e-06, 4.974257968932691e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:08<00:00,  1.06it/s, loss=0.102]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:44<00:00,  2.18it/s]\n",
      "epoch 3: trn_loss = 0.1022, val_loss = 0.1000, trn_score = 0.4529, val_score = 0.4478\n",
      "model (best score) saved\n",
      "lr :  [2.3268220525837457e-06, 2.3268220525837457e-06, 2.3268220525837457e-05]\n",
      "100%|████████████████████████████| 391/391 [06:09<00:00,  1.06it/s, loss=0.0984]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:45<00:00,  2.17it/s]\n",
      "epoch 4: trn_loss = 0.0984, val_loss = 0.0989, trn_score = 0.4442, val_score = 0.4454\n",
      "model (best score) saved\n",
      "lr :  [5.996867213330993e-07, 5.996867213330993e-07, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [06:15<00:00,  1.04it/s, loss=0.0951]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:45<00:00,  2.16it/s]\n",
      "epoch 5: trn_loss = 0.0951, val_loss = 0.0992, trn_score = 0.4365, val_score = 0.4461\n",
      "\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-10-16 19:12:39.656623: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 19:12:39.656645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [06:17<00:00,  1.04it/s, loss=0.334]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:43<00:00,  2.25it/s]\n",
      "epoch 1: trn_loss = 0.3340, val_loss = 0.1159, trn_score = 1.0017, val_score = 0.4829\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:19<00:00,  1.03it/s, loss=0.108]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:43<00:00,  2.24it/s]\n",
      "epoch 2: trn_loss = 0.1082, val_loss = 0.1098, trn_score = 0.4662, val_score = 0.4697\n",
      "model (best score) saved\n",
      "lr :  [4.974257968932691e-06, 4.974257968932691e-06, 4.974257968932691e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:20<00:00,  1.03it/s, loss=0.104]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:43<00:00,  2.23it/s]\n",
      "epoch 3: trn_loss = 0.1040, val_loss = 0.1086, trn_score = 0.4570, val_score = 0.4670\n",
      "model (best score) saved\n",
      "lr :  [2.3268220525837457e-06, 2.3268220525837457e-06, 2.3268220525837457e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:16<00:00,  1.04it/s, loss=0.103]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:44<00:00,  2.22it/s]\n",
      "epoch 4: trn_loss = 0.1030, val_loss = 0.1054, trn_score = 0.4549, val_score = 0.4598\n",
      "model (best score) saved\n",
      "lr :  [5.996867213330993e-07, 5.996867213330993e-07, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [06:14<00:00,  1.04it/s, loss=0.0953]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:43<00:00,  2.24it/s]\n",
      "epoch 5: trn_loss = 0.0953, val_loss = 0.1045, trn_score = 0.4369, val_score = 0.4579\n",
      "model (best score) saved\n",
      "\n",
      "torch 1.10.1\n",
      "args.mode =  train\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "2022-10-16 19:48:09.887151: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 19:48:09.887173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "self.warmup_ratio =  0.1\n",
      "self.num_train_steps =  1955\n",
      "num_warmup_steps =  195\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|█████████████████████████████| 391/391 [06:22<00:00,  1.02it/s, loss=0.309]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:43<00:00,  2.27it/s]\n",
      "epoch 1: trn_loss = 0.3092, val_loss = 0.1121, trn_score = 0.9547, val_score = 0.4750\n",
      "model (best score) saved\n",
      "lr :  [8.224468037456969e-06, 8.224468037456969e-06, 8.224468037456969e-05]\n",
      "100%|█████████████████████████████| 391/391 [06:14<00:00,  1.04it/s, loss=0.106]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:43<00:00,  2.27it/s]\n",
      "epoch 2: trn_loss = 0.1061, val_loss = 0.1058, trn_score = 0.4616, val_score = 0.4607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model (best score) saved\n",
      "lr :  [4.974257968932691e-06, 4.974257968932691e-06, 4.974257968932691e-05]\n",
      "100%|███████████████████████████████| 391/391 [06:12<00:00,  1.05it/s, loss=0.1]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:42<00:00,  2.29it/s]\n",
      "epoch 3: trn_loss = 0.1000, val_loss = 0.1050, trn_score = 0.4480, val_score = 0.4590\n",
      "model (best score) saved\n",
      "lr :  [2.3268220525837457e-06, 2.3268220525837457e-06, 2.3268220525837457e-05]\n",
      "100%|████████████████████████████| 391/391 [06:15<00:00,  1.04it/s, loss=0.0977]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:42<00:00,  2.28it/s]\n",
      "epoch 4: trn_loss = 0.0977, val_loss = 0.1029, trn_score = 0.4425, val_score = 0.4543\n",
      "model (best score) saved\n",
      "lr :  [5.996867213330993e-07, 5.996867213330993e-07, 5.996867213330992e-06]\n",
      "100%|████████████████████████████| 391/391 [06:04<00:00,  1.07it/s, loss=0.0936]\n",
      "100%|███████████████████████████████████████████| 98/98 [00:42<00:00,  2.31it/s]\n",
      "epoch 5: trn_loss = 0.0936, val_loss = 0.1048, trn_score = 0.4332, val_score = 0.4588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for FOLD in [1,2,3,4]:\n",
    "    INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "    FOLD_PATH = '../../00_EDA/00_v1_02/result/'\n",
    "    MODE = 'train'\n",
    "    EPOCHS = 5\n",
    "    STOP_EPOCH = 5\n",
    "    RESTART = 1\n",
    "    NUM_CYCLES = EPOCHS\n",
    "    PRETRAIN_PATH = 'none' #f'result/{VERSION}/model_seed{SEED}_fold{FOLD}_epoch{EPOCHS}_pseudo.pth'\n",
    "\n",
    "    !python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "    --lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "    --epochs $EPOCHS --hidden_drop_prob $HIDDEN_DROP_PROB --p_drop $P_DROP \\\n",
    "    --accumulate_grad_batches $ACCUM_STEP --rnn $RNN --warmup_ratio $WARMUP_RATIO --loss $LOSS --aug $AUG --head $HEAD \\\n",
    "    --mixup_alpha $MIXUP_ALPHA --p_aug $P_AUG --aug_stop_epoch $AUG_STOP_EPOCH \\\n",
    "    --msd $MSD --multi_layers $MULTI_LAYERS \\\n",
    "    --eval_step_start_epoch $EVAL_STEP_START_EPOCH --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "    --num_labels $NUM_LABELS --num_labels_2 $NUM_LABELS_2 \\\n",
    "    --restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --freeze_layers $FREEZE \\\n",
    "    --mt $MULTI_TASK --w_mt $W_MT \\\n",
    "    --awp $AWP --awp_lr $AWP_LR --awp_eps $AWP_EPS --awp_start_epoch $AWP_START_EPOCH \\\n",
    "    --pretrained_detector_path $PRETRAINED_DETECTOR_PATH --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "    --scheduler $SCHEDULER --num_cycles $NUM_CYCLES --check_pointing $CP \\\n",
    "    --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN \\\n",
    "    --gradient_clip_val $GRAD_CLIP \\\n",
    "    --input_path $INPUT_PATH --mode $MODE --pretrain_path $PRETRAIN_PATH --max_length $MAX_LEN \\\n",
    "    --crop_prob $CROP_PROB --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = '../../input/feedback-prize-english-language-learning/'\n",
    "FOLD_PATH = '../../00_EDA/00_v1_02/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.1\n",
      "2022-10-16 20:42:40.844602: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 20:42:40.844623: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3128, 8)\n",
      "val_df.shape =  (783, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:40<00:00,  2.44it/s]\n",
      "val_loss=0.1017, val_score=0.4510\n",
      "essay_ids.shape =  (783,)\n",
      "preds.shape =  (783, 6)\n",
      "labels.shape =  (783, 6)\n",
      "losses.shape =  (783, 6)\n",
      "embeds.shape =  (783, 768)\n",
      "torch 1.10.1\n",
      "2022-10-16 20:43:37.798615: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 20:43:37.798638: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:35<00:00,  2.72it/s]\n",
      "val_loss=0.0995, val_score=0.4470\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n",
      "torch 1.10.1\n",
      "2022-10-16 20:44:30.338739: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 20:44:30.338759: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:38<00:00,  2.55it/s]\n",
      "val_loss=0.0989, val_score=0.4454\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n",
      "torch 1.10.1\n",
      "2022-10-16 20:45:25.529111: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 20:45:25.529134: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:37<00:00,  2.63it/s]\n",
      "val_loss=0.1045, val_score=0.4579\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n",
      "torch 1.10.1\n",
      "2022-10-16 20:46:19.515668: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:\n",
      "2022-10-16 20:46:19.515692: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (3911, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (3129, 8)\n",
      "val_df.shape =  (782, 8)\n",
      "100%|███████████████████████████████████████████| 98/98 [00:36<00:00,  2.66it/s]\n",
      "val_loss=0.1029, val_score=0.4543\n",
      "essay_ids.shape =  (782,)\n",
      "preds.shape =  (782, 6)\n",
      "labels.shape =  (782, 6)\n",
      "losses.shape =  (782, 6)\n",
      "embeds.shape =  (782, 768)\n"
     ]
    }
   ],
   "source": [
    "for FOLD in [0,1,2,3,4]:\n",
    "    WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}.pth'\n",
    "    !python ../$VERSION/validation.py --model $MODEL --version $VERSION \\\n",
    "    --fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "    --rnn $RNN --loss $LOSS --mt $MULTI_TASK --num_labels $NUM_LABELS --loss $LOSS --weight_path $WEIGHT_PATH \\\n",
    "    --window_size $WINDOW_SIZE --inner_len $INNER_LEN --edge_len $EDGE_LEN --max_length $MAX_LEN \\\n",
    "    --pooling $POOLING --num_pooling_layers $NUM_POOLING_LAYERS --head $HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_fold = 5\n",
    "\n",
    "preds = []\n",
    "for fold in range(num_fold):\n",
    "    tmp_df = pd.read_csv(f'./result/{VERSION}/pred_fold{fold}.csv')\n",
    "    embeds = np.load(f'./result/{VERSION}/embeds_fold{fold}.npz')['arr_0']\n",
    "    tmp_df['embed'] = embeds.tolist()\n",
    "    preds.append(tmp_df)\n",
    "    \n",
    "pred_df = pd.concat(preds, axis=0).reset_index(drop=True)\n",
    "train_df = pd.read_csv('../../input/feedback-prize-english-language-learning/train.csv')\n",
    "\n",
    "oof_df = train_df[['text_id']].merge(pred_df, on='text_id', how='left')\n",
    "oof_df.to_csv(f'./result/{VERSION}/oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3911, 14),\n",
       " text_id             0\n",
       " cohesion            0\n",
       " syntax              0\n",
       " vocabulary          0\n",
       " phraseology         0\n",
       " grammar             0\n",
       " conventions         0\n",
       " loss_cohesion       0\n",
       " loss_syntax         0\n",
       " loss_vocabulary     0\n",
       " loss_phraseology    0\n",
       " loss_grammar        0\n",
       " loss_conventions    0\n",
       " embed               0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df.shape, oof_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.158237</td>\n",
       "      <td>3.054563</td>\n",
       "      <td>3.239536</td>\n",
       "      <td>3.121990</td>\n",
       "      <td>3.031928</td>\n",
       "      <td>3.087741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477282</td>\n",
       "      <td>0.490461</td>\n",
       "      <td>0.419045</td>\n",
       "      <td>0.491270</td>\n",
       "      <td>0.541664</td>\n",
       "      <td>0.529057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.307701</td>\n",
       "      <td>1.447039</td>\n",
       "      <td>1.822759</td>\n",
       "      <td>1.426927</td>\n",
       "      <td>1.462611</td>\n",
       "      <td>0.971463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.828785</td>\n",
       "      <td>2.706457</td>\n",
       "      <td>2.951776</td>\n",
       "      <td>2.775788</td>\n",
       "      <td>2.604236</td>\n",
       "      <td>2.709151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.155614</td>\n",
       "      <td>3.033757</td>\n",
       "      <td>3.212811</td>\n",
       "      <td>3.106489</td>\n",
       "      <td>3.009755</td>\n",
       "      <td>3.074707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.480163</td>\n",
       "      <td>3.383813</td>\n",
       "      <td>3.511338</td>\n",
       "      <td>3.461677</td>\n",
       "      <td>3.409141</td>\n",
       "      <td>3.455867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.818566</td>\n",
       "      <td>4.748018</td>\n",
       "      <td>4.966004</td>\n",
       "      <td>4.750876</td>\n",
       "      <td>4.790921</td>\n",
       "      <td>4.639637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cohesion       syntax   vocabulary  phraseology      grammar  \\\n",
       "count  3911.000000  3911.000000  3911.000000  3911.000000  3911.000000   \n",
       "mean      3.158237     3.054563     3.239536     3.121990     3.031928   \n",
       "std       0.477282     0.490461     0.419045     0.491270     0.541664   \n",
       "min       1.307701     1.447039     1.822759     1.426927     1.462611   \n",
       "25%       2.828785     2.706457     2.951776     2.775788     2.604236   \n",
       "50%       3.155614     3.033757     3.212811     3.106489     3.009755   \n",
       "75%       3.480163     3.383813     3.511338     3.461677     3.409141   \n",
       "max       4.818566     4.748018     4.966004     4.750876     4.790921   \n",
       "\n",
       "       conventions  \n",
       "count  3911.000000  \n",
       "mean      3.087741  \n",
       "std       0.529057  \n",
       "min       0.971463  \n",
       "25%       2.709151  \n",
       "50%       3.074707  \n",
       "75%       3.455867  \n",
       "max       4.639637  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>3911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.127077</td>\n",
       "      <td>3.028254</td>\n",
       "      <td>3.235745</td>\n",
       "      <td>3.116850</td>\n",
       "      <td>3.032856</td>\n",
       "      <td>3.081053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.662542</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>0.583148</td>\n",
       "      <td>0.655997</td>\n",
       "      <td>0.699841</td>\n",
       "      <td>0.671450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cohesion       syntax   vocabulary  phraseology      grammar  \\\n",
       "count  3911.000000  3911.000000  3911.000000  3911.000000  3911.000000   \n",
       "mean      3.127077     3.028254     3.235745     3.116850     3.032856   \n",
       "std       0.662542     0.644399     0.583148     0.655997     0.699841   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       2.500000     2.500000     3.000000     2.500000     2.500000   \n",
       "50%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.500000     3.500000     3.500000     3.500000     3.500000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "       conventions  \n",
       "count  3911.000000  \n",
       "mean      3.081053  \n",
       "std       0.671450  \n",
       "min       1.000000  \n",
       "25%       2.500000  \n",
       "50%       3.000000  \n",
       "75%       3.500000  \n",
       "max       5.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_cohesion</th>\n",
       "      <th>loss_syntax</th>\n",
       "      <th>loss_vocabulary</th>\n",
       "      <th>loss_phraseology</th>\n",
       "      <th>loss_grammar</th>\n",
       "      <th>loss_conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.911000e+03</td>\n",
       "      <td>3.911000e+03</td>\n",
       "      <td>3.911000e+03</td>\n",
       "      <td>3.911000e+03</td>\n",
       "      <td>3.911000e+03</td>\n",
       "      <td>3.911000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.163642e-01</td>\n",
       "      <td>9.838057e-02</td>\n",
       "      <td>8.453796e-02</td>\n",
       "      <td>1.016823e-01</td>\n",
       "      <td>1.102055e-01</td>\n",
       "      <td>9.789030e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.520434e-01</td>\n",
       "      <td>1.347640e-01</td>\n",
       "      <td>1.185563e-01</td>\n",
       "      <td>1.369676e-01</td>\n",
       "      <td>1.501473e-01</td>\n",
       "      <td>1.352744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.448927e-08</td>\n",
       "      <td>3.133494e-10</td>\n",
       "      <td>7.833734e-09</td>\n",
       "      <td>9.960786e-09</td>\n",
       "      <td>3.577963e-08</td>\n",
       "      <td>1.114245e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.413724e-02</td>\n",
       "      <td>1.022602e-02</td>\n",
       "      <td>8.159376e-03</td>\n",
       "      <td>1.039181e-02</td>\n",
       "      <td>1.114462e-02</td>\n",
       "      <td>9.596785e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.788495e-02</td>\n",
       "      <td>4.470771e-02</td>\n",
       "      <td>3.689358e-02</td>\n",
       "      <td>4.829042e-02</td>\n",
       "      <td>5.121730e-02</td>\n",
       "      <td>4.665108e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.564626e-01</td>\n",
       "      <td>1.359555e-01</td>\n",
       "      <td>1.094967e-01</td>\n",
       "      <td>1.379755e-01</td>\n",
       "      <td>1.500605e-01</td>\n",
       "      <td>1.292939e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.244686e+00</td>\n",
       "      <td>1.189890e+00</td>\n",
       "      <td>1.124851e+00</td>\n",
       "      <td>1.061622e+00</td>\n",
       "      <td>1.203399e+00</td>\n",
       "      <td>1.198697e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss_cohesion   loss_syntax  loss_vocabulary  loss_phraseology  \\\n",
       "count   3.911000e+03  3.911000e+03     3.911000e+03      3.911000e+03   \n",
       "mean    1.163642e-01  9.838057e-02     8.453796e-02      1.016823e-01   \n",
       "std     1.520434e-01  1.347640e-01     1.185563e-01      1.369676e-01   \n",
       "min     1.448927e-08  3.133494e-10     7.833734e-09      9.960786e-09   \n",
       "25%     1.413724e-02  1.022602e-02     8.159376e-03      1.039181e-02   \n",
       "50%     5.788495e-02  4.470771e-02     3.689358e-02      4.829042e-02   \n",
       "75%     1.564626e-01  1.359555e-01     1.094967e-01      1.379755e-01   \n",
       "max     1.244686e+00  1.189890e+00     1.124851e+00      1.061622e+00   \n",
       "\n",
       "       loss_grammar  loss_conventions  \n",
       "count  3.911000e+03      3.911000e+03  \n",
       "mean   1.102055e-01      9.789030e-02  \n",
       "std    1.501473e-01      1.352744e-01  \n",
       "min    3.577963e-08      1.114245e-09  \n",
       "25%    1.114462e-02      9.596785e-03  \n",
       "50%    5.121730e-02      4.665108e-02  \n",
       "75%    1.500605e-01      1.292939e-01  \n",
       "max    1.203399e+00      1.198697e+00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [f\"loss_{c}\" for c in ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']]\n",
    "oof_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohesion : 0.4840\n",
      "syntax : 0.4447\n",
      "vocabulary : 0.4118\n",
      "phraseology : 0.4519\n",
      "grammar : 0.4712\n",
      "conventions : 0.4436\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_metric(pred, gt):\n",
    "    '''\n",
    "    pred : (num_data, num_labels)\n",
    "    gt : (num_data, num_labels)\n",
    "    '''\n",
    "    score = np.sqrt(np.mean((pred - gt)**2, axis=0))\n",
    "    score = score.mean()\n",
    "    return score\n",
    "\n",
    "for c in ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']:\n",
    "    score = calc_metric(oof_df[c].values, train_df[c].values)\n",
    "    print(\"{} : {:.4f}\".format(c, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis - Check Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695459</td>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.666151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>0.695459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680562</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.700025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.680562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>0.654852</td>\n",
       "      <td>0.664292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.666842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.654852</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.700025</td>\n",
       "      <td>0.664292</td>\n",
       "      <td>0.666842</td>\n",
       "      <td>0.673301</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "cohesion     1.000000  0.695459    0.666151     0.690058  0.638689   \n",
       "syntax       0.695459  1.000000    0.680562     0.725467  0.709525   \n",
       "vocabulary   0.666151  0.680562    1.000000     0.735261  0.654852   \n",
       "phraseology  0.690058  0.725467    0.735261     1.000000  0.719746   \n",
       "grammar      0.638689  0.709525    0.654852     0.719746  1.000000   \n",
       "conventions  0.666151  0.700025    0.664292     0.666842  0.673301   \n",
       "\n",
       "             conventions  \n",
       "cohesion        0.666151  \n",
       "syntax          0.700025  \n",
       "vocabulary      0.664292  \n",
       "phraseology     0.666842  \n",
       "grammar         0.673301  \n",
       "conventions     1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "train_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969978</td>\n",
       "      <td>0.954364</td>\n",
       "      <td>0.935843</td>\n",
       "      <td>0.853764</td>\n",
       "      <td>0.907680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>0.969978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965306</td>\n",
       "      <td>0.969973</td>\n",
       "      <td>0.931004</td>\n",
       "      <td>0.935918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>0.954364</td>\n",
       "      <td>0.965306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974574</td>\n",
       "      <td>0.906493</td>\n",
       "      <td>0.917716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>0.935843</td>\n",
       "      <td>0.969973</td>\n",
       "      <td>0.974574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954536</td>\n",
       "      <td>0.897063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>0.853764</td>\n",
       "      <td>0.931004</td>\n",
       "      <td>0.906493</td>\n",
       "      <td>0.954536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>0.907680</td>\n",
       "      <td>0.935918</td>\n",
       "      <td>0.917716</td>\n",
       "      <td>0.897063</td>\n",
       "      <td>0.873818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "cohesion     1.000000  0.969978    0.954364     0.935843  0.853764   \n",
       "syntax       0.969978  1.000000    0.965306     0.969973  0.931004   \n",
       "vocabulary   0.954364  0.965306    1.000000     0.974574  0.906493   \n",
       "phraseology  0.935843  0.969973    0.974574     1.000000  0.954536   \n",
       "grammar      0.853764  0.931004    0.906493     0.954536  1.000000   \n",
       "conventions  0.907680  0.935918    0.917716     0.897063  0.873818   \n",
       "\n",
       "             conventions  \n",
       "cohesion        0.907680  \n",
       "syntax          0.935918  \n",
       "vocabulary      0.917716  \n",
       "phraseology     0.897063  \n",
       "grammar         0.873818  \n",
       "conventions     1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "oof_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
