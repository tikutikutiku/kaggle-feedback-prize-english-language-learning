{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takesako/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('../../input/feedback-prize-english-language-learning/train.csv')\n",
    "\n",
    "\n",
    "model_path_list = [\n",
    "    '../../01_Baseline/exp/result/01_v1_27/oof_df.csv', # deberta-v3-base\n",
    "    '../../01_Baseline/exp/result/01_v1_43/oof_df.csv', # deberta-v3-large\n",
    "    '../../01_Baseline/exp/result/01_v1_24/oof_df.csv', # deberta-base\n",
    "    '../../01_Baseline/exp/result/01_v1_25/oof_df.csv', # deberta-large\n",
    "    '../../01_Baseline/exp/result/01_v1_45/oof_df.csv', # roberta-large\n",
    "]\n",
    "\n",
    "oof_df_list = [\n",
    "    pd.read_csv(model_path) for model_path in model_path_list\n",
    "]\n",
    "\n",
    "for oof_df in oof_df_list:\n",
    "    oof_df = train_df[['text_id']].merge(oof_df, how='left', on='text_id')\n",
    "    \n",
    "num_models = len(model_path_list)\n",
    "\n",
    "TARGET_COLS = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "\n",
    "stack_df = oof_df_list[0][['text_id']]\n",
    "for i in range(num_models):\n",
    "    oof_df = oof_df_list[i]\n",
    "    for col in TARGET_COLS:\n",
    "        stack_df[f'{col}_{i}'] = oof_df[col].values\n",
    "        \n",
    "        \n",
    "train_df = train_df[['text_id']+TARGET_COLS].merge(stack_df, on='text_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>cohesion_0</th>\n",
       "      <th>syntax_0</th>\n",
       "      <th>vocabulary_0</th>\n",
       "      <th>...</th>\n",
       "      <th>vocabulary_3</th>\n",
       "      <th>phraseology_3</th>\n",
       "      <th>grammar_3</th>\n",
       "      <th>conventions_3</th>\n",
       "      <th>cohesion_4</th>\n",
       "      <th>syntax_4</th>\n",
       "      <th>vocabulary_4</th>\n",
       "      <th>phraseology_4</th>\n",
       "      <th>grammar_4</th>\n",
       "      <th>conventions_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.885453</td>\n",
       "      <td>2.860759</td>\n",
       "      <td>3.071929</td>\n",
       "      <td>...</td>\n",
       "      <td>3.120876</td>\n",
       "      <td>3.150779</td>\n",
       "      <td>3.208785</td>\n",
       "      <td>2.907158</td>\n",
       "      <td>2.923405</td>\n",
       "      <td>2.831063</td>\n",
       "      <td>2.912158</td>\n",
       "      <td>3.103420</td>\n",
       "      <td>3.065863</td>\n",
       "      <td>2.769381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.521122</td>\n",
       "      <td>2.440580</td>\n",
       "      <td>2.711392</td>\n",
       "      <td>...</td>\n",
       "      <td>2.850693</td>\n",
       "      <td>2.709044</td>\n",
       "      <td>2.587369</td>\n",
       "      <td>2.587832</td>\n",
       "      <td>2.536946</td>\n",
       "      <td>2.380513</td>\n",
       "      <td>2.800518</td>\n",
       "      <td>2.592651</td>\n",
       "      <td>2.413749</td>\n",
       "      <td>2.427189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.843849</td>\n",
       "      <td>2.967711</td>\n",
       "      <td>2.917809</td>\n",
       "      <td>...</td>\n",
       "      <td>3.094973</td>\n",
       "      <td>2.980881</td>\n",
       "      <td>3.055136</td>\n",
       "      <td>2.833445</td>\n",
       "      <td>2.829473</td>\n",
       "      <td>2.762232</td>\n",
       "      <td>2.867777</td>\n",
       "      <td>2.815092</td>\n",
       "      <td>2.863168</td>\n",
       "      <td>2.902894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.642689</td>\n",
       "      <td>3.595627</td>\n",
       "      <td>3.678757</td>\n",
       "      <td>...</td>\n",
       "      <td>3.846789</td>\n",
       "      <td>3.849410</td>\n",
       "      <td>3.860160</td>\n",
       "      <td>4.146064</td>\n",
       "      <td>3.548078</td>\n",
       "      <td>3.525499</td>\n",
       "      <td>3.610355</td>\n",
       "      <td>3.724175</td>\n",
       "      <td>3.698088</td>\n",
       "      <td>3.715907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.658665</td>\n",
       "      <td>2.453293</td>\n",
       "      <td>2.795006</td>\n",
       "      <td>...</td>\n",
       "      <td>2.709118</td>\n",
       "      <td>2.647390</td>\n",
       "      <td>2.518007</td>\n",
       "      <td>2.496209</td>\n",
       "      <td>2.536176</td>\n",
       "      <td>2.404460</td>\n",
       "      <td>2.743569</td>\n",
       "      <td>2.690457</td>\n",
       "      <td>2.631302</td>\n",
       "      <td>2.564926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  \\\n",
       "0  0016926B079C       3.5     3.5         3.0          3.0      4.0   \n",
       "1  0022683E9EA5       2.5     2.5         3.0          2.0      2.0   \n",
       "2  00299B378633       3.0     3.5         3.0          3.0      3.0   \n",
       "3  003885A45F42       4.5     4.5         4.5          4.5      4.0   \n",
       "4  0049B1DF5CCC       2.5     3.0         3.0          3.0      2.5   \n",
       "\n",
       "   conventions  cohesion_0  syntax_0  vocabulary_0  ...  vocabulary_3  \\\n",
       "0          3.0    2.885453  2.860759      3.071929  ...      3.120876   \n",
       "1          2.5    2.521122  2.440580      2.711392  ...      2.850693   \n",
       "2          2.5    2.843849  2.967711      2.917809  ...      3.094973   \n",
       "3          5.0    3.642689  3.595627      3.678757  ...      3.846789   \n",
       "4          2.5    2.658665  2.453293      2.795006  ...      2.709118   \n",
       "\n",
       "   phraseology_3  grammar_3  conventions_3  cohesion_4  syntax_4  \\\n",
       "0       3.150779   3.208785       2.907158    2.923405  2.831063   \n",
       "1       2.709044   2.587369       2.587832    2.536946  2.380513   \n",
       "2       2.980881   3.055136       2.833445    2.829473  2.762232   \n",
       "3       3.849410   3.860160       4.146064    3.548078  3.525499   \n",
       "4       2.647390   2.518007       2.496209    2.536176  2.404460   \n",
       "\n",
       "   vocabulary_4  phraseology_4  grammar_4  conventions_4  \n",
       "0      2.912158       3.103420   3.065863       2.769381  \n",
       "1      2.800518       2.592651   2.413749       2.427189  \n",
       "2      2.867777       2.815092   2.863168       2.902894  \n",
       "3      3.610355       3.724175   3.698088       3.715907  \n",
       "4      2.743569       2.690457   2.631302       2.564926  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in stack_df.columns if col!='text_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load folds...\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as opj\n",
    "\n",
    "class args:\n",
    "    fold_path = '../../00_EDA/00_v1_02/result/'\n",
    "    num_fold = 5\n",
    "    \n",
    "fold_path = args.fold_path\n",
    "import joblib\n",
    "print('load folds...')\n",
    "trn_ids_list = joblib.load(opj(fold_path,f'trn_ids_list.joblib'))\n",
    "val_ids_list = joblib.load(opj(fold_path,f'val_ids_list.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_feature_importance(model):\n",
    "    feature_importance = model.get_feature_importance()\n",
    "    fi_df = pd.DataFrame({'importance':feature_importance, 'features':feature_cols})\n",
    "    fi_df = fi_df.sort_values('importance', ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(range(len(fi_df)),\n",
    "            fi_df['importance'].values,\n",
    "            tick_label=fi_df['features'].values)\n",
    "    plt.xlabel('importance')\n",
    "    plt.ylabel('features')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "params = {\n",
    "    'random_state':45, \n",
    "    'n_estimators':20000,\n",
    "    'loss_function':'RMSE',\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "def calc_metric(pred, gt):\n",
    "    '''\n",
    "    pred : (num_data, num_labels)\n",
    "    gt : (num_data, num_labels)\n",
    "    '''\n",
    "    score = np.sqrt(np.mean((pred - gt)**2, axis=0))\n",
    "    score = score.mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0 : CV=0.4486\n",
      "fold1 : CV=0.4447\n",
      "fold2 : CV=0.4447\n",
      "fold3 : CV=0.4539\n",
      "fold4 : CV=0.4546\n",
      "CV=0.4493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import pickle\n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "\n",
    "score_list = []\n",
    "oof_df = []\n",
    "\n",
    "for fold in range(args.num_fold):\n",
    "    trn_df = train_df[train_df['text_id'].isin(trn_ids_list[fold])].reset_index(drop=True)\n",
    "    val_df = train_df[train_df['text_id'].isin(val_ids_list[fold])].reset_index(drop=True)\n",
    "    preds = np.zeros((len(val_df), len(TARGET_COLS)))\n",
    "\n",
    "    for i,col in enumerate(TARGET_COLS):\n",
    "        tmp_feature_cols = [c for c in feature_cols if c.startswith(col)]\n",
    "        pool_trn = catboost.Pool(trn_df[tmp_feature_cols].values, label=trn_df[col].values, cat_features=cat_features)\n",
    "        pool_val = catboost.Pool(val_df[tmp_feature_cols].values, label=val_df[col].values, cat_features=cat_features)\n",
    "\n",
    "        model = catboost.CatBoostRegressor(**params)\n",
    "        model.fit(pool_trn, \n",
    "                  eval_set=[pool_val], \n",
    "                  verbose=0, \n",
    "                  early_stopping_rounds=100,\n",
    "                 )\n",
    "\n",
    "        pred = model.predict(pool_val)\n",
    "        preds[:,i] = pred\n",
    "        # save model\n",
    "        joblib.dump(model, f'./result/cat_fold{fold}_{i}.joblib')\n",
    "        # plot\n",
    "        #show_feature_importance(model)\n",
    "    \n",
    "    target = val_df[TARGET_COLS].values\n",
    "    score = calc_metric(preds, target)\n",
    "    print('fold{} : CV={:.4f}'.format(fold, score))\n",
    "    score_list.append(score)\n",
    "    for i,col in enumerate(TARGET_COLS):\n",
    "        val_df[f'oof_{col}'] = preds[:,i]\n",
    "    oof_df.append(val_df)\n",
    "    \n",
    "CV = sum(score_list) / len(score_list)\n",
    "print('CV={:.4f}'.format(CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oof_df = pd.concat(oof_df).reset_index(drop=True)\n",
    "oof_df = train_df[['text_id']].merge(oof_df, on='text_id', how='left')\n",
    "oof_df.to_csv(f'./result/oof_cat.csv', index=False)\n",
    "print(oof_df.shape)\n",
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in oof_df.columns if col.startswith('oof_')]\n",
    "\n",
    "oof_score = calc_metric(oof_df[cols].values, oof_df[TARGET_COLS].values)\n",
    "print('oof={:.4f}'.format(oof_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
